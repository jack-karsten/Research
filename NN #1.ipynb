{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Load data\n",
    "data1 = pd.read_csv('NQ_1min_continuous_adjusted.txt', names=[\"times\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "\n",
    "# Convert 'times' to datetime\n",
    "data1['times'] = pd.to_datetime(data1['times'])\n",
    "\n",
    "# Extract time from datetime for filtering\n",
    "data1['time'] = data1['times'].dt.time\n",
    "data1['date']= data1['times'].dt.date\n",
    "\n",
    "# Filter for opening range and day range\n",
    "opening_range = data1[(data1['time'] >= datetime.time(9, 30)) & (data1['time'] <= datetime.time(10, 29))]\n",
    "open_to_close = data1[(data1['time'] >= datetime.time(9, 30)) & (data1['time'] <= datetime.time(15, 59))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_to_close = data1[(data1['time'] >= datetime.time(9, 30)) & (data1['time'] <= datetime.time(15, 59))]\n",
    "data1_daily = open_to_close.groupby('date').agg(close=('close', 'last'),open=('open','first'))\n",
    "data1_daily['prev_close'] = data1_daily['close'].shift(1)\n",
    "data1_daily['gap'] = data1_daily['open'] -data1_daily['prev_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_volume_ib</th>\n",
       "      <th>high_ib</th>\n",
       "      <th>low_ib</th>\n",
       "      <th>open_ib</th>\n",
       "      <th>opening_range_high_rel</th>\n",
       "      <th>opening_range_low_rel</th>\n",
       "      <th>atr_ib</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>63123</td>\n",
       "      <td>2506.00</td>\n",
       "      <td>2488.75</td>\n",
       "      <td>2498.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>-9.25</td>\n",
       "      <td>17.25</td>\n",
       "      <td>2461.25</td>\n",
       "      <td>2498.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>75091</td>\n",
       "      <td>2470.25</td>\n",
       "      <td>2452.00</td>\n",
       "      <td>2460.00</td>\n",
       "      <td>10.25</td>\n",
       "      <td>-8.00</td>\n",
       "      <td>18.25</td>\n",
       "      <td>2462.00</td>\n",
       "      <td>2460.00</td>\n",
       "      <td>2461.25</td>\n",
       "      <td>-1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>94984</td>\n",
       "      <td>2436.75</td>\n",
       "      <td>2413.50</td>\n",
       "      <td>2435.25</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-21.75</td>\n",
       "      <td>23.25</td>\n",
       "      <td>2372.75</td>\n",
       "      <td>2435.25</td>\n",
       "      <td>2462.00</td>\n",
       "      <td>-26.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>115195</td>\n",
       "      <td>2383.50</td>\n",
       "      <td>2348.50</td>\n",
       "      <td>2378.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>-29.50</td>\n",
       "      <td>35.00</td>\n",
       "      <td>2368.00</td>\n",
       "      <td>2378.00</td>\n",
       "      <td>2372.75</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <td>99037</td>\n",
       "      <td>2391.75</td>\n",
       "      <td>2368.75</td>\n",
       "      <td>2372.50</td>\n",
       "      <td>19.25</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>23.00</td>\n",
       "      <td>2318.25</td>\n",
       "      <td>2372.50</td>\n",
       "      <td>2368.00</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-24</th>\n",
       "      <td>118141</td>\n",
       "      <td>13134.00</td>\n",
       "      <td>13054.00</td>\n",
       "      <td>13077.50</td>\n",
       "      <td>56.50</td>\n",
       "      <td>-23.50</td>\n",
       "      <td>80.00</td>\n",
       "      <td>13059.25</td>\n",
       "      <td>13077.50</td>\n",
       "      <td>13088.25</td>\n",
       "      <td>-10.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-25</th>\n",
       "      <td>132208</td>\n",
       "      <td>13015.50</td>\n",
       "      <td>12937.00</td>\n",
       "      <td>12988.25</td>\n",
       "      <td>27.25</td>\n",
       "      <td>-51.25</td>\n",
       "      <td>78.50</td>\n",
       "      <td>12808.50</td>\n",
       "      <td>12988.25</td>\n",
       "      <td>13059.25</td>\n",
       "      <td>-71.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-26</th>\n",
       "      <td>143777</td>\n",
       "      <td>12967.50</td>\n",
       "      <td>12896.50</td>\n",
       "      <td>12950.25</td>\n",
       "      <td>17.25</td>\n",
       "      <td>-53.75</td>\n",
       "      <td>71.00</td>\n",
       "      <td>12882.50</td>\n",
       "      <td>12950.25</td>\n",
       "      <td>12808.50</td>\n",
       "      <td>141.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>163783</td>\n",
       "      <td>13092.00</td>\n",
       "      <td>13013.50</td>\n",
       "      <td>13040.75</td>\n",
       "      <td>51.25</td>\n",
       "      <td>-27.25</td>\n",
       "      <td>78.50</td>\n",
       "      <td>13231.25</td>\n",
       "      <td>13040.75</td>\n",
       "      <td>12882.50</td>\n",
       "      <td>158.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28</th>\n",
       "      <td>160172</td>\n",
       "      <td>13292.25</td>\n",
       "      <td>13172.25</td>\n",
       "      <td>13220.25</td>\n",
       "      <td>72.00</td>\n",
       "      <td>-48.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>13323.50</td>\n",
       "      <td>13220.25</td>\n",
       "      <td>13231.25</td>\n",
       "      <td>-11.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3951 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_volume_ib   high_ib    low_ib   open_ib  \\\n",
       "date                                                        \n",
       "2008-01-02            63123   2506.00   2488.75   2498.00   \n",
       "2008-01-03            75091   2470.25   2452.00   2460.00   \n",
       "2008-01-04            94984   2436.75   2413.50   2435.25   \n",
       "2008-01-07           115195   2383.50   2348.50   2378.00   \n",
       "2008-01-08            99037   2391.75   2368.75   2372.50   \n",
       "...                     ...       ...       ...       ...   \n",
       "2023-04-24           118141  13134.00  13054.00  13077.50   \n",
       "2023-04-25           132208  13015.50  12937.00  12988.25   \n",
       "2023-04-26           143777  12967.50  12896.50  12950.25   \n",
       "2023-04-27           163783  13092.00  13013.50  13040.75   \n",
       "2023-04-28           160172  13292.25  13172.25  13220.25   \n",
       "\n",
       "            opening_range_high_rel  opening_range_low_rel  atr_ib     close  \\\n",
       "date                                                                          \n",
       "2008-01-02                    8.00                  -9.25   17.25   2461.25   \n",
       "2008-01-03                   10.25                  -8.00   18.25   2462.00   \n",
       "2008-01-04                    1.50                 -21.75   23.25   2372.75   \n",
       "2008-01-07                    5.50                 -29.50   35.00   2368.00   \n",
       "2008-01-08                   19.25                  -3.75   23.00   2318.25   \n",
       "...                            ...                    ...     ...       ...   \n",
       "2023-04-24                   56.50                 -23.50   80.00  13059.25   \n",
       "2023-04-25                   27.25                 -51.25   78.50  12808.50   \n",
       "2023-04-26                   17.25                 -53.75   71.00  12882.50   \n",
       "2023-04-27                   51.25                 -27.25   78.50  13231.25   \n",
       "2023-04-28                   72.00                 -48.00  120.00  13323.50   \n",
       "\n",
       "                open  prev_close     gap  \n",
       "date                                      \n",
       "2008-01-02   2498.00         NaN     NaN  \n",
       "2008-01-03   2460.00     2461.25   -1.25  \n",
       "2008-01-04   2435.25     2462.00  -26.75  \n",
       "2008-01-07   2378.00     2372.75    5.25  \n",
       "2008-01-08   2372.50     2368.00    4.50  \n",
       "...              ...         ...     ...  \n",
       "2023-04-24  13077.50    13088.25  -10.75  \n",
       "2023-04-25  12988.25    13059.25  -71.00  \n",
       "2023-04-26  12950.25    12808.50  141.75  \n",
       "2023-04-27  13040.75    12882.50  158.25  \n",
       "2023-04-28  13220.25    13231.25  -11.00  \n",
       "\n",
       "[3951 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opening_range_stats = opening_range.groupby('date').agg( total_volume_ib = ('volume','sum'),high_ib=('high', 'max'), low_ib=('low', 'min'),open_ib=('open','first') ) # your aggregation here\n",
    "opening_range_stats['opening_range_high_rel'] = opening_range_stats['high_ib'] - opening_range_stats['open_ib']\n",
    "opening_range_stats['opening_range_low_rel'] = opening_range_stats['low_ib'] - opening_range_stats['open_ib']\n",
    "opening_range_stats['atr_ib'] = opening_range.groupby('date').apply(lambda x: x['high'].max() - x['low'].min())\n",
    "# Merge features into a single dataframe\n",
    "features_df = opening_range_stats.merge(data1_daily, left_index=True, right_index=True, how='left')\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = features_df.corr()\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your target variable based on what you want to predict. For instance, if you want to predict whether the closing price is higher than the opening price:\n",
    "features_df['target'] = (features_df['close'] - features_df['open'] > 0).astype(int)\n",
    "\n",
    "# Select relevant features for the model\n",
    "feature_columns = ['opening_range_high_rel', 'opening_range_low_rel', 'gap', 'total_volume_ib', 'atr_ib']  # Replace with your actual feature column names\n",
    "final_feature_set = features_df[feature_columns + ['target']]\n",
    "final_feature_set= final_feature_set.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming 'final_feature_set' is your DataFrame with all the features and target\n",
    "X = final_feature_set[feature_columns].values\n",
    "y = final_feature_set['target'].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "89/89 [==============================] - 4s 10ms/step - loss: 0.6793 - accuracy: 0.5876 - val_loss: 0.6638 - val_accuracy: 0.6203\n",
      "Epoch 2/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6494 - val_loss: 0.6526 - val_accuracy: 0.6361\n",
      "Epoch 3/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.6786 - val_loss: 0.6468 - val_accuracy: 0.6677\n",
      "Epoch 4/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6881 - val_loss: 0.6448 - val_accuracy: 0.6899\n",
      "Epoch 5/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.6937 - val_loss: 0.6335 - val_accuracy: 0.6930\n",
      "Epoch 6/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.6878 - val_loss: 0.6298 - val_accuracy: 0.6930\n",
      "Epoch 7/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.6944 - val_loss: 0.6276 - val_accuracy: 0.6867\n",
      "Epoch 8/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.6944 - val_loss: 0.6247 - val_accuracy: 0.7057\n",
      "Epoch 9/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.6955 - val_loss: 0.6254 - val_accuracy: 0.7025\n",
      "Epoch 10/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.6902 - val_loss: 0.6283 - val_accuracy: 0.6772\n",
      "Epoch 11/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.6951 - val_loss: 0.6229 - val_accuracy: 0.6962\n",
      "Epoch 12/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6920 - val_loss: 0.6222 - val_accuracy: 0.6994\n",
      "Epoch 13/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.6916 - val_loss: 0.6237 - val_accuracy: 0.7025\n",
      "Epoch 14/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.6888 - val_loss: 0.6220 - val_accuracy: 0.6899\n",
      "Epoch 15/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.6994 - val_loss: 0.6302 - val_accuracy: 0.6835\n",
      "Epoch 16/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.6906 - val_loss: 0.6251 - val_accuracy: 0.6930\n",
      "Epoch 17/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6983 - val_loss: 0.6250 - val_accuracy: 0.6994\n",
      "Epoch 18/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6906 - val_loss: 0.6248 - val_accuracy: 0.6994\n",
      "Epoch 19/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.6927 - val_loss: 0.6283 - val_accuracy: 0.6867\n",
      "Epoch 20/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.6937 - val_loss: 0.6274 - val_accuracy: 0.6899\n",
      "Epoch 21/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.6937 - val_loss: 0.6257 - val_accuracy: 0.6867\n",
      "Epoch 22/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.6980 - val_loss: 0.6247 - val_accuracy: 0.6962\n",
      "Epoch 23/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6948 - val_loss: 0.6258 - val_accuracy: 0.6930\n",
      "Epoch 24/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.6955 - val_loss: 0.6252 - val_accuracy: 0.6930\n",
      "Epoch 25/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.7001 - val_loss: 0.6247 - val_accuracy: 0.6994\n",
      "Epoch 26/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.6990 - val_loss: 0.6276 - val_accuracy: 0.6899\n",
      "Epoch 27/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6962 - val_loss: 0.6292 - val_accuracy: 0.6835\n",
      "Epoch 28/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.6980 - val_loss: 0.6248 - val_accuracy: 0.6994\n",
      "Epoch 29/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.6976 - val_loss: 0.6294 - val_accuracy: 0.6867\n",
      "Epoch 30/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6962 - val_loss: 0.6255 - val_accuracy: 0.6962\n",
      "Epoch 31/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6969 - val_loss: 0.6256 - val_accuracy: 0.6962\n",
      "Epoch 32/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.6990 - val_loss: 0.6276 - val_accuracy: 0.6867\n",
      "Epoch 33/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.6941 - val_loss: 0.6302 - val_accuracy: 0.6867\n",
      "Epoch 34/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.6966 - val_loss: 0.6322 - val_accuracy: 0.6804\n",
      "Epoch 35/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6969 - val_loss: 0.6253 - val_accuracy: 0.7025\n",
      "Epoch 36/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6944 - val_loss: 0.6292 - val_accuracy: 0.6899\n",
      "Epoch 37/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.6934 - val_loss: 0.6245 - val_accuracy: 0.7057\n",
      "Epoch 38/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.6973 - val_loss: 0.6273 - val_accuracy: 0.7057\n",
      "Epoch 39/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6934 - val_loss: 0.6290 - val_accuracy: 0.6962\n",
      "Epoch 40/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6948 - val_loss: 0.6269 - val_accuracy: 0.7057\n",
      "Epoch 41/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.6980 - val_loss: 0.6283 - val_accuracy: 0.7057\n",
      "Epoch 42/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.6980 - val_loss: 0.6342 - val_accuracy: 0.6835\n",
      "Epoch 43/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.7015 - val_loss: 0.6262 - val_accuracy: 0.7025\n",
      "Epoch 44/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6962 - val_loss: 0.6298 - val_accuracy: 0.7089\n",
      "Epoch 45/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.6973 - val_loss: 0.6290 - val_accuracy: 0.6930\n",
      "Epoch 46/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.6962 - val_loss: 0.6282 - val_accuracy: 0.7025\n",
      "Epoch 47/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6920 - val_loss: 0.6266 - val_accuracy: 0.6962\n",
      "Epoch 48/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.6955 - val_loss: 0.6296 - val_accuracy: 0.6962\n",
      "Epoch 49/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.6976 - val_loss: 0.6263 - val_accuracy: 0.6899\n",
      "Epoch 50/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7018 - val_loss: 0.6319 - val_accuracy: 0.6962\n",
      "Epoch 51/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6955 - val_loss: 0.6324 - val_accuracy: 0.6899\n",
      "Epoch 52/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.6937 - val_loss: 0.6291 - val_accuracy: 0.6962\n",
      "Epoch 53/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.6966 - val_loss: 0.6313 - val_accuracy: 0.7089\n",
      "Epoch 54/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.6994 - val_loss: 0.6272 - val_accuracy: 0.7025\n",
      "Epoch 55/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6934 - val_loss: 0.6312 - val_accuracy: 0.6930\n",
      "Epoch 56/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.6937 - val_loss: 0.6303 - val_accuracy: 0.6899\n",
      "Epoch 57/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.6969 - val_loss: 0.6283 - val_accuracy: 0.7025\n",
      "Epoch 58/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.6980 - val_loss: 0.6278 - val_accuracy: 0.7057\n",
      "Epoch 59/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.6976 - val_loss: 0.6327 - val_accuracy: 0.6772\n",
      "Epoch 60/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6934 - val_loss: 0.6305 - val_accuracy: 0.6994\n",
      "Epoch 61/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.6951 - val_loss: 0.6264 - val_accuracy: 0.6962\n",
      "Epoch 62/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.6951 - val_loss: 0.6285 - val_accuracy: 0.6994\n",
      "Epoch 63/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.6937 - val_loss: 0.6295 - val_accuracy: 0.6994\n",
      "Epoch 64/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.6941 - val_loss: 0.6313 - val_accuracy: 0.7025\n",
      "Epoch 65/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7015 - val_loss: 0.6348 - val_accuracy: 0.6930\n",
      "Epoch 66/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7022 - val_loss: 0.6284 - val_accuracy: 0.6994\n",
      "Epoch 67/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.6969 - val_loss: 0.6344 - val_accuracy: 0.6899\n",
      "Epoch 68/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.6948 - val_loss: 0.6358 - val_accuracy: 0.6930\n",
      "Epoch 69/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.6969 - val_loss: 0.6302 - val_accuracy: 0.6994\n",
      "Epoch 70/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6983 - val_loss: 0.6294 - val_accuracy: 0.7025\n",
      "Epoch 71/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6951 - val_loss: 0.6311 - val_accuracy: 0.6899\n",
      "Epoch 72/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.6969 - val_loss: 0.6340 - val_accuracy: 0.7025\n",
      "Epoch 73/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.6969 - val_loss: 0.6301 - val_accuracy: 0.7057\n",
      "Epoch 74/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7001 - val_loss: 0.6335 - val_accuracy: 0.6899\n",
      "Epoch 75/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.6969 - val_loss: 0.6337 - val_accuracy: 0.7025\n",
      "Epoch 76/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.6973 - val_loss: 0.6347 - val_accuracy: 0.6962\n",
      "Epoch 77/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6987 - val_loss: 0.6286 - val_accuracy: 0.7089\n",
      "Epoch 78/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.6980 - val_loss: 0.6320 - val_accuracy: 0.6994\n",
      "Epoch 79/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.6983 - val_loss: 0.6280 - val_accuracy: 0.7025\n",
      "Epoch 80/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.6994 - val_loss: 0.6320 - val_accuracy: 0.6930\n",
      "Epoch 81/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.7001 - val_loss: 0.6347 - val_accuracy: 0.6899\n",
      "Epoch 82/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.7060 - val_loss: 0.6362 - val_accuracy: 0.6899\n",
      "Epoch 83/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6983 - val_loss: 0.6369 - val_accuracy: 0.6835\n",
      "Epoch 84/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.6966 - val_loss: 0.6312 - val_accuracy: 0.7057\n",
      "Epoch 85/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.6941 - val_loss: 0.6333 - val_accuracy: 0.6867\n",
      "Epoch 86/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.6959 - val_loss: 0.6329 - val_accuracy: 0.6962\n",
      "Epoch 87/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6920 - val_loss: 0.6333 - val_accuracy: 0.6962\n",
      "Epoch 88/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.6959 - val_loss: 0.6334 - val_accuracy: 0.7089\n",
      "Epoch 89/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.7008 - val_loss: 0.6316 - val_accuracy: 0.7120\n",
      "Epoch 90/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.6920 - val_loss: 0.6314 - val_accuracy: 0.6994\n",
      "Epoch 91/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6955 - val_loss: 0.6311 - val_accuracy: 0.6962\n",
      "Epoch 92/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.6990 - val_loss: 0.6314 - val_accuracy: 0.7089\n",
      "Epoch 93/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7025 - val_loss: 0.6308 - val_accuracy: 0.7120\n",
      "Epoch 94/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7001 - val_loss: 0.6306 - val_accuracy: 0.7057\n",
      "Epoch 95/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.6976 - val_loss: 0.6326 - val_accuracy: 0.7089\n",
      "Epoch 96/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.7011 - val_loss: 0.6316 - val_accuracy: 0.7057\n",
      "Epoch 97/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.6983 - val_loss: 0.6315 - val_accuracy: 0.6994\n",
      "Epoch 98/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7004 - val_loss: 0.6314 - val_accuracy: 0.7120\n",
      "Epoch 99/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6955 - val_loss: 0.6313 - val_accuracy: 0.7120\n",
      "Epoch 100/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.6997 - val_loss: 0.6331 - val_accuracy: 0.7057\n",
      "Epoch 101/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6959 - val_loss: 0.6348 - val_accuracy: 0.6994\n",
      "Epoch 102/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.7004 - val_loss: 0.6343 - val_accuracy: 0.7057\n",
      "Epoch 103/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7025 - val_loss: 0.6301 - val_accuracy: 0.7089\n",
      "Epoch 104/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.6969 - val_loss: 0.6321 - val_accuracy: 0.7120\n",
      "Epoch 105/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.6962 - val_loss: 0.6316 - val_accuracy: 0.7089\n",
      "Epoch 106/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.6930 - val_loss: 0.6308 - val_accuracy: 0.7120\n",
      "Epoch 107/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.6997 - val_loss: 0.6324 - val_accuracy: 0.6994\n",
      "Epoch 108/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.6983 - val_loss: 0.6318 - val_accuracy: 0.7120\n",
      "Epoch 109/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.6966 - val_loss: 0.6348 - val_accuracy: 0.7089\n",
      "Epoch 110/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6937 - val_loss: 0.6337 - val_accuracy: 0.7120\n",
      "Epoch 111/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7011 - val_loss: 0.6352 - val_accuracy: 0.7025\n",
      "Epoch 112/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.6983 - val_loss: 0.6337 - val_accuracy: 0.6962\n",
      "Epoch 113/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.6962 - val_loss: 0.6341 - val_accuracy: 0.6930\n",
      "Epoch 114/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.6948 - val_loss: 0.6325 - val_accuracy: 0.7025\n",
      "Epoch 115/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7004 - val_loss: 0.6377 - val_accuracy: 0.7057\n",
      "Epoch 116/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.6997 - val_loss: 0.6301 - val_accuracy: 0.7152\n",
      "Epoch 117/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.6962 - val_loss: 0.6404 - val_accuracy: 0.6804\n",
      "Epoch 118/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6930 - val_loss: 0.6337 - val_accuracy: 0.7057\n",
      "Epoch 119/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7011 - val_loss: 0.6354 - val_accuracy: 0.7025\n",
      "Epoch 120/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6990 - val_loss: 0.6356 - val_accuracy: 0.6994\n",
      "Epoch 121/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.6987 - val_loss: 0.6361 - val_accuracy: 0.7057\n",
      "Epoch 122/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7011 - val_loss: 0.6345 - val_accuracy: 0.7057\n",
      "Epoch 123/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6948 - val_loss: 0.6343 - val_accuracy: 0.6994\n",
      "Epoch 124/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.6973 - val_loss: 0.6356 - val_accuracy: 0.7025\n",
      "Epoch 125/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.6941 - val_loss: 0.6320 - val_accuracy: 0.7120\n",
      "Epoch 126/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.6987 - val_loss: 0.6352 - val_accuracy: 0.7120\n",
      "Epoch 127/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6987 - val_loss: 0.6358 - val_accuracy: 0.7057\n",
      "Epoch 128/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.7001 - val_loss: 0.6328 - val_accuracy: 0.7120\n",
      "Epoch 129/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6944 - val_loss: 0.6367 - val_accuracy: 0.6962\n",
      "Epoch 130/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.6973 - val_loss: 0.6394 - val_accuracy: 0.6962\n",
      "Epoch 131/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.6941 - val_loss: 0.6344 - val_accuracy: 0.7152\n",
      "Epoch 132/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.7050 - val_loss: 0.6353 - val_accuracy: 0.7057\n",
      "Epoch 133/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.6966 - val_loss: 0.6359 - val_accuracy: 0.7025\n",
      "Epoch 134/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.6927 - val_loss: 0.6379 - val_accuracy: 0.6994\n",
      "Epoch 135/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7011 - val_loss: 0.6386 - val_accuracy: 0.6962\n",
      "Epoch 136/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6944 - val_loss: 0.6347 - val_accuracy: 0.6994\n",
      "Epoch 137/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.6997 - val_loss: 0.6324 - val_accuracy: 0.7120\n",
      "Epoch 138/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.6948 - val_loss: 0.6342 - val_accuracy: 0.7057\n",
      "Epoch 139/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7001 - val_loss: 0.6365 - val_accuracy: 0.7025\n",
      "Epoch 140/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.6962 - val_loss: 0.6347 - val_accuracy: 0.7120\n",
      "Epoch 141/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7022 - val_loss: 0.6361 - val_accuracy: 0.7057\n",
      "Epoch 142/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.6973 - val_loss: 0.6391 - val_accuracy: 0.7025\n",
      "Epoch 143/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.6980 - val_loss: 0.6369 - val_accuracy: 0.6962\n",
      "Epoch 144/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6969 - val_loss: 0.6374 - val_accuracy: 0.7120\n",
      "Epoch 145/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6987 - val_loss: 0.6358 - val_accuracy: 0.7057\n",
      "Epoch 146/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.6997 - val_loss: 0.6341 - val_accuracy: 0.6962\n",
      "Epoch 147/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7029 - val_loss: 0.6352 - val_accuracy: 0.7025\n",
      "Epoch 148/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7004 - val_loss: 0.6351 - val_accuracy: 0.7089\n",
      "Epoch 149/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7011 - val_loss: 0.6353 - val_accuracy: 0.6994\n",
      "Epoch 150/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.6923 - val_loss: 0.6352 - val_accuracy: 0.6994\n",
      "Epoch 151/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.6959 - val_loss: 0.6386 - val_accuracy: 0.7025\n",
      "Epoch 152/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.6959 - val_loss: 0.6378 - val_accuracy: 0.6994\n",
      "Epoch 153/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.6987 - val_loss: 0.6380 - val_accuracy: 0.6962\n",
      "Epoch 154/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.6980 - val_loss: 0.6363 - val_accuracy: 0.7057\n",
      "Epoch 155/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7022 - val_loss: 0.6384 - val_accuracy: 0.7057\n",
      "Epoch 156/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.6944 - val_loss: 0.6353 - val_accuracy: 0.6994\n",
      "Epoch 157/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.6990 - val_loss: 0.6409 - val_accuracy: 0.6994\n",
      "Epoch 158/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6941 - val_loss: 0.6395 - val_accuracy: 0.7025\n",
      "Epoch 159/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.6966 - val_loss: 0.6381 - val_accuracy: 0.6994\n",
      "Epoch 160/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.6951 - val_loss: 0.6363 - val_accuracy: 0.7089\n",
      "Epoch 161/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.6997 - val_loss: 0.6386 - val_accuracy: 0.6962\n",
      "Epoch 162/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.6966 - val_loss: 0.6394 - val_accuracy: 0.7025\n",
      "Epoch 163/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7029 - val_loss: 0.6352 - val_accuracy: 0.7089\n",
      "Epoch 164/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7036 - val_loss: 0.6334 - val_accuracy: 0.6962\n",
      "Epoch 165/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7001 - val_loss: 0.6353 - val_accuracy: 0.7089\n",
      "Epoch 166/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.6980 - val_loss: 0.6353 - val_accuracy: 0.6930\n",
      "Epoch 167/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.6994 - val_loss: 0.6349 - val_accuracy: 0.7025\n",
      "Epoch 168/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6934 - val_loss: 0.6350 - val_accuracy: 0.6994\n",
      "Epoch 169/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7004 - val_loss: 0.6434 - val_accuracy: 0.7025\n",
      "Epoch 170/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7004 - val_loss: 0.6373 - val_accuracy: 0.6994\n",
      "Epoch 171/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6976 - val_loss: 0.6450 - val_accuracy: 0.6930\n",
      "Epoch 172/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7036 - val_loss: 0.6432 - val_accuracy: 0.6804\n",
      "Epoch 173/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.6983 - val_loss: 0.6359 - val_accuracy: 0.7057\n",
      "Epoch 174/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7022 - val_loss: 0.6362 - val_accuracy: 0.7057\n",
      "Epoch 175/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6973 - val_loss: 0.6355 - val_accuracy: 0.6994\n",
      "Epoch 176/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.7015 - val_loss: 0.6383 - val_accuracy: 0.7120\n",
      "Epoch 177/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.7001 - val_loss: 0.6401 - val_accuracy: 0.6962\n",
      "Epoch 178/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.6980 - val_loss: 0.6396 - val_accuracy: 0.7025\n",
      "Epoch 179/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7001 - val_loss: 0.6413 - val_accuracy: 0.6930\n",
      "Epoch 180/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7011 - val_loss: 0.6418 - val_accuracy: 0.6962\n",
      "Epoch 181/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7015 - val_loss: 0.6415 - val_accuracy: 0.6899\n",
      "Epoch 182/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7008 - val_loss: 0.6414 - val_accuracy: 0.6930\n",
      "Epoch 183/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.7015 - val_loss: 0.6400 - val_accuracy: 0.6994\n",
      "Epoch 184/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7001 - val_loss: 0.6407 - val_accuracy: 0.6930\n",
      "Epoch 185/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7036 - val_loss: 0.6395 - val_accuracy: 0.7025\n",
      "Epoch 186/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7008 - val_loss: 0.6392 - val_accuracy: 0.6867\n",
      "Epoch 187/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.6997 - val_loss: 0.6412 - val_accuracy: 0.6994\n",
      "Epoch 188/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7011 - val_loss: 0.6367 - val_accuracy: 0.6867\n",
      "Epoch 189/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.6941 - val_loss: 0.6361 - val_accuracy: 0.7057\n",
      "Epoch 190/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6990 - val_loss: 0.6389 - val_accuracy: 0.6899\n",
      "Epoch 191/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.6962 - val_loss: 0.6390 - val_accuracy: 0.7057\n",
      "Epoch 192/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7008 - val_loss: 0.6375 - val_accuracy: 0.7025\n",
      "Epoch 193/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.6997 - val_loss: 0.6391 - val_accuracy: 0.6899\n",
      "Epoch 194/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.6990 - val_loss: 0.6375 - val_accuracy: 0.6962\n",
      "Epoch 195/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7004 - val_loss: 0.6448 - val_accuracy: 0.6994\n",
      "Epoch 196/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.6997 - val_loss: 0.6430 - val_accuracy: 0.6930\n",
      "Epoch 197/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.6990 - val_loss: 0.6416 - val_accuracy: 0.6930\n",
      "Epoch 198/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7029 - val_loss: 0.6415 - val_accuracy: 0.7025\n",
      "Epoch 199/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6997 - val_loss: 0.6424 - val_accuracy: 0.6899\n",
      "Epoch 200/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6987 - val_loss: 0.6436 - val_accuracy: 0.7025\n",
      "Epoch 201/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.6976 - val_loss: 0.6389 - val_accuracy: 0.6962\n",
      "Epoch 202/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.6983 - val_loss: 0.6395 - val_accuracy: 0.7057\n",
      "Epoch 203/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.6994 - val_loss: 0.6380 - val_accuracy: 0.6899\n",
      "Epoch 204/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.6990 - val_loss: 0.6378 - val_accuracy: 0.6899\n",
      "Epoch 205/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7015 - val_loss: 0.6394 - val_accuracy: 0.6899\n",
      "Epoch 206/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.7022 - val_loss: 0.6366 - val_accuracy: 0.6962\n",
      "Epoch 207/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.6987 - val_loss: 0.6402 - val_accuracy: 0.7025\n",
      "Epoch 208/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7039 - val_loss: 0.6378 - val_accuracy: 0.6867\n",
      "Epoch 209/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7011 - val_loss: 0.6390 - val_accuracy: 0.6930\n",
      "Epoch 210/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7011 - val_loss: 0.6406 - val_accuracy: 0.6930\n",
      "Epoch 211/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.6930 - val_loss: 0.6359 - val_accuracy: 0.6899\n",
      "Epoch 212/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.6969 - val_loss: 0.6381 - val_accuracy: 0.6962\n",
      "Epoch 213/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.6976 - val_loss: 0.6474 - val_accuracy: 0.6994\n",
      "Epoch 214/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7025 - val_loss: 0.6421 - val_accuracy: 0.6867\n",
      "Epoch 215/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.6983 - val_loss: 0.6400 - val_accuracy: 0.6867\n",
      "Epoch 216/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.7001 - val_loss: 0.6396 - val_accuracy: 0.6930\n",
      "Epoch 217/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.6969 - val_loss: 0.6448 - val_accuracy: 0.6899\n",
      "Epoch 218/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7022 - val_loss: 0.6411 - val_accuracy: 0.6930\n",
      "Epoch 219/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7046 - val_loss: 0.6430 - val_accuracy: 0.6867\n",
      "Epoch 220/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7025 - val_loss: 0.6382 - val_accuracy: 0.6962\n",
      "Epoch 221/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.6990 - val_loss: 0.6352 - val_accuracy: 0.7089\n",
      "Epoch 222/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7015 - val_loss: 0.6397 - val_accuracy: 0.6930\n",
      "Epoch 223/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.6976 - val_loss: 0.6397 - val_accuracy: 0.6962\n",
      "Epoch 224/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7057 - val_loss: 0.6428 - val_accuracy: 0.6899\n",
      "Epoch 225/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.6959 - val_loss: 0.6390 - val_accuracy: 0.6899\n",
      "Epoch 226/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.7064 - val_loss: 0.6377 - val_accuracy: 0.6930\n",
      "Epoch 227/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7029 - val_loss: 0.6417 - val_accuracy: 0.6930\n",
      "Epoch 228/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7036 - val_loss: 0.6430 - val_accuracy: 0.6899\n",
      "Epoch 229/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.6990 - val_loss: 0.6386 - val_accuracy: 0.7057\n",
      "Epoch 230/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7011 - val_loss: 0.6417 - val_accuracy: 0.6962\n",
      "Epoch 231/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6987 - val_loss: 0.6434 - val_accuracy: 0.6930\n",
      "Epoch 232/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.7060 - val_loss: 0.6393 - val_accuracy: 0.7025\n",
      "Epoch 233/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.6966 - val_loss: 0.6444 - val_accuracy: 0.6867\n",
      "Epoch 234/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7015 - val_loss: 0.6455 - val_accuracy: 0.6867\n",
      "Epoch 235/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7057 - val_loss: 0.6420 - val_accuracy: 0.6930\n",
      "Epoch 236/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.6994 - val_loss: 0.6389 - val_accuracy: 0.6867\n",
      "Epoch 237/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7001 - val_loss: 0.6402 - val_accuracy: 0.6994\n",
      "Epoch 238/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.6983 - val_loss: 0.6421 - val_accuracy: 0.6994\n",
      "Epoch 239/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.6997 - val_loss: 0.6394 - val_accuracy: 0.6962\n",
      "Epoch 240/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7015 - val_loss: 0.6421 - val_accuracy: 0.6899\n",
      "Epoch 241/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7050 - val_loss: 0.6430 - val_accuracy: 0.6899\n",
      "Epoch 242/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7029 - val_loss: 0.6371 - val_accuracy: 0.6962\n",
      "Epoch 243/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.6980 - val_loss: 0.6425 - val_accuracy: 0.6930\n",
      "Epoch 244/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7018 - val_loss: 0.6397 - val_accuracy: 0.6962\n",
      "Epoch 245/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7043 - val_loss: 0.6419 - val_accuracy: 0.6962\n",
      "Epoch 246/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7015 - val_loss: 0.6414 - val_accuracy: 0.6835\n",
      "Epoch 247/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7018 - val_loss: 0.6413 - val_accuracy: 0.6994\n",
      "Epoch 248/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7025 - val_loss: 0.6433 - val_accuracy: 0.6930\n",
      "Epoch 249/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.6994 - val_loss: 0.6443 - val_accuracy: 0.6867\n",
      "Epoch 250/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.7029 - val_loss: 0.6420 - val_accuracy: 0.6899\n",
      "Epoch 251/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7029 - val_loss: 0.6419 - val_accuracy: 0.6994\n",
      "Epoch 252/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7043 - val_loss: 0.6444 - val_accuracy: 0.6899\n",
      "Epoch 253/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7011 - val_loss: 0.6443 - val_accuracy: 0.6962\n",
      "Epoch 254/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7022 - val_loss: 0.6419 - val_accuracy: 0.6962\n",
      "Epoch 255/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7011 - val_loss: 0.6423 - val_accuracy: 0.6962\n",
      "Epoch 256/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7018 - val_loss: 0.6479 - val_accuracy: 0.6930\n",
      "Epoch 257/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7089 - val_loss: 0.6454 - val_accuracy: 0.6930\n",
      "Epoch 258/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.7011 - val_loss: 0.6488 - val_accuracy: 0.6930\n",
      "Epoch 259/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7008 - val_loss: 0.6439 - val_accuracy: 0.6867\n",
      "Epoch 260/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7008 - val_loss: 0.6433 - val_accuracy: 0.6994\n",
      "Epoch 261/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.6983 - val_loss: 0.6443 - val_accuracy: 0.6930\n",
      "Epoch 262/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.6987 - val_loss: 0.6416 - val_accuracy: 0.6930\n",
      "Epoch 263/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.7057 - val_loss: 0.6410 - val_accuracy: 0.6930\n",
      "Epoch 264/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7039 - val_loss: 0.6383 - val_accuracy: 0.7025\n",
      "Epoch 265/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7018 - val_loss: 0.6390 - val_accuracy: 0.7025\n",
      "Epoch 266/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7004 - val_loss: 0.6411 - val_accuracy: 0.6994\n",
      "Epoch 267/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7082 - val_loss: 0.6409 - val_accuracy: 0.7025\n",
      "Epoch 268/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.6973 - val_loss: 0.6456 - val_accuracy: 0.6899\n",
      "Epoch 269/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7050 - val_loss: 0.6408 - val_accuracy: 0.6899\n",
      "Epoch 270/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7018 - val_loss: 0.6419 - val_accuracy: 0.6994\n",
      "Epoch 271/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.7018 - val_loss: 0.6419 - val_accuracy: 0.7057\n",
      "Epoch 272/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7032 - val_loss: 0.6455 - val_accuracy: 0.7057\n",
      "Epoch 273/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.7025 - val_loss: 0.6441 - val_accuracy: 0.7025\n",
      "Epoch 274/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7008 - val_loss: 0.6426 - val_accuracy: 0.6994\n",
      "Epoch 275/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7043 - val_loss: 0.6412 - val_accuracy: 0.6994\n",
      "Epoch 276/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7011 - val_loss: 0.6445 - val_accuracy: 0.6994\n",
      "Epoch 277/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7050 - val_loss: 0.6443 - val_accuracy: 0.6962\n",
      "Epoch 278/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7001 - val_loss: 0.6437 - val_accuracy: 0.6899\n",
      "Epoch 279/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7008 - val_loss: 0.6396 - val_accuracy: 0.6899\n",
      "Epoch 280/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.7025 - val_loss: 0.6440 - val_accuracy: 0.7025\n",
      "Epoch 281/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7057 - val_loss: 0.6463 - val_accuracy: 0.6867\n",
      "Epoch 282/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7004 - val_loss: 0.6471 - val_accuracy: 0.6962\n",
      "Epoch 283/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7018 - val_loss: 0.6405 - val_accuracy: 0.6994\n",
      "Epoch 284/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7008 - val_loss: 0.6403 - val_accuracy: 0.6994\n",
      "Epoch 285/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.6980 - val_loss: 0.6388 - val_accuracy: 0.7025\n",
      "Epoch 286/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7029 - val_loss: 0.6438 - val_accuracy: 0.7057\n",
      "Epoch 287/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7004 - val_loss: 0.6433 - val_accuracy: 0.6962\n",
      "Epoch 288/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7022 - val_loss: 0.6457 - val_accuracy: 0.6930\n",
      "Epoch 289/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7015 - val_loss: 0.6421 - val_accuracy: 0.7057\n",
      "Epoch 290/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7015 - val_loss: 0.6445 - val_accuracy: 0.6930\n",
      "Epoch 291/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7036 - val_loss: 0.6417 - val_accuracy: 0.7025\n",
      "Epoch 292/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7036 - val_loss: 0.6467 - val_accuracy: 0.7025\n",
      "Epoch 293/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.7046 - val_loss: 0.6444 - val_accuracy: 0.6930\n",
      "Epoch 294/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7022 - val_loss: 0.6448 - val_accuracy: 0.6930\n",
      "Epoch 295/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7025 - val_loss: 0.6431 - val_accuracy: 0.6930\n",
      "Epoch 296/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7053 - val_loss: 0.6429 - val_accuracy: 0.6962\n",
      "Epoch 297/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7039 - val_loss: 0.6464 - val_accuracy: 0.6930\n",
      "Epoch 298/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7029 - val_loss: 0.6440 - val_accuracy: 0.7025\n",
      "Epoch 299/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.6994 - val_loss: 0.6481 - val_accuracy: 0.7025\n",
      "Epoch 300/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.6976 - val_loss: 0.6424 - val_accuracy: 0.7025\n",
      "Epoch 301/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7032 - val_loss: 0.6448 - val_accuracy: 0.6899\n",
      "Epoch 302/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.7022 - val_loss: 0.6480 - val_accuracy: 0.6930\n",
      "Epoch 303/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7018 - val_loss: 0.6441 - val_accuracy: 0.7025\n",
      "Epoch 304/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.6983 - val_loss: 0.6438 - val_accuracy: 0.7025\n",
      "Epoch 305/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.6980 - val_loss: 0.6444 - val_accuracy: 0.6899\n",
      "Epoch 306/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7018 - val_loss: 0.6464 - val_accuracy: 0.6899\n",
      "Epoch 307/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7050 - val_loss: 0.6462 - val_accuracy: 0.6930\n",
      "Epoch 308/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7001 - val_loss: 0.6436 - val_accuracy: 0.6994\n",
      "Epoch 309/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7008 - val_loss: 0.6507 - val_accuracy: 0.6994\n",
      "Epoch 310/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7053 - val_loss: 0.6447 - val_accuracy: 0.6962\n",
      "Epoch 311/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7018 - val_loss: 0.6460 - val_accuracy: 0.6962\n",
      "Epoch 312/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7025 - val_loss: 0.6450 - val_accuracy: 0.6962\n",
      "Epoch 313/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.7001 - val_loss: 0.6472 - val_accuracy: 0.6962\n",
      "Epoch 314/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.6980 - val_loss: 0.6445 - val_accuracy: 0.6994\n",
      "Epoch 315/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7078 - val_loss: 0.6480 - val_accuracy: 0.6962\n",
      "Epoch 316/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7057 - val_loss: 0.6494 - val_accuracy: 0.6962\n",
      "Epoch 317/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7001 - val_loss: 0.6478 - val_accuracy: 0.6994\n",
      "Epoch 318/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7043 - val_loss: 0.6456 - val_accuracy: 0.7025\n",
      "Epoch 319/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7025 - val_loss: 0.6470 - val_accuracy: 0.6962\n",
      "Epoch 320/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7036 - val_loss: 0.6449 - val_accuracy: 0.7025\n",
      "Epoch 321/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7015 - val_loss: 0.6467 - val_accuracy: 0.6962\n",
      "Epoch 322/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7060 - val_loss: 0.6449 - val_accuracy: 0.6962\n",
      "Epoch 323/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7015 - val_loss: 0.6438 - val_accuracy: 0.6994\n",
      "Epoch 324/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7064 - val_loss: 0.6435 - val_accuracy: 0.7057\n",
      "Epoch 325/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7046 - val_loss: 0.6459 - val_accuracy: 0.6899\n",
      "Epoch 326/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7046 - val_loss: 0.6451 - val_accuracy: 0.6994\n",
      "Epoch 327/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7043 - val_loss: 0.6447 - val_accuracy: 0.7025\n",
      "Epoch 328/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7060 - val_loss: 0.6489 - val_accuracy: 0.6899\n",
      "Epoch 329/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7043 - val_loss: 0.6419 - val_accuracy: 0.7089\n",
      "Epoch 330/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.6997 - val_loss: 0.6414 - val_accuracy: 0.6994\n",
      "Epoch 331/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7089 - val_loss: 0.6478 - val_accuracy: 0.6962\n",
      "Epoch 332/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7018 - val_loss: 0.6450 - val_accuracy: 0.6994\n",
      "Epoch 333/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7046 - val_loss: 0.6436 - val_accuracy: 0.6962\n",
      "Epoch 334/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7082 - val_loss: 0.6494 - val_accuracy: 0.6899\n",
      "Epoch 335/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7025 - val_loss: 0.6462 - val_accuracy: 0.6994\n",
      "Epoch 336/1000\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7050 - val_loss: 0.6454 - val_accuracy: 0.6867\n",
      "Epoch 337/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7036 - val_loss: 0.6439 - val_accuracy: 0.6899\n",
      "Epoch 338/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.7064 - val_loss: 0.6460 - val_accuracy: 0.7057\n",
      "Epoch 339/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.6994 - val_loss: 0.6540 - val_accuracy: 0.6930\n",
      "Epoch 340/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7075 - val_loss: 0.6507 - val_accuracy: 0.7025\n",
      "Epoch 341/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7022 - val_loss: 0.6524 - val_accuracy: 0.6867\n",
      "Epoch 342/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.7050 - val_loss: 0.6459 - val_accuracy: 0.6930\n",
      "Epoch 343/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7068 - val_loss: 0.6465 - val_accuracy: 0.6930\n",
      "Epoch 344/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.7046 - val_loss: 0.6491 - val_accuracy: 0.6962\n",
      "Epoch 345/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.6990 - val_loss: 0.6470 - val_accuracy: 0.6962\n",
      "Epoch 346/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7029 - val_loss: 0.6488 - val_accuracy: 0.6899\n",
      "Epoch 347/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7060 - val_loss: 0.6481 - val_accuracy: 0.6899\n",
      "Epoch 348/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7022 - val_loss: 0.6473 - val_accuracy: 0.6962\n",
      "Epoch 349/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7064 - val_loss: 0.6491 - val_accuracy: 0.6994\n",
      "Epoch 350/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7008 - val_loss: 0.6489 - val_accuracy: 0.6994\n",
      "Epoch 351/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7068 - val_loss: 0.6470 - val_accuracy: 0.6994\n",
      "Epoch 352/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7036 - val_loss: 0.6542 - val_accuracy: 0.6994\n",
      "Epoch 353/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7036 - val_loss: 0.6522 - val_accuracy: 0.6930\n",
      "Epoch 354/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7018 - val_loss: 0.6521 - val_accuracy: 0.6962\n",
      "Epoch 355/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7015 - val_loss: 0.6513 - val_accuracy: 0.6962\n",
      "Epoch 356/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7032 - val_loss: 0.6486 - val_accuracy: 0.6962\n",
      "Epoch 357/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7001 - val_loss: 0.6482 - val_accuracy: 0.6930\n",
      "Epoch 358/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7011 - val_loss: 0.6464 - val_accuracy: 0.6930\n",
      "Epoch 359/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7068 - val_loss: 0.6495 - val_accuracy: 0.7025\n",
      "Epoch 360/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.7008 - val_loss: 0.6494 - val_accuracy: 0.6962\n",
      "Epoch 361/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7060 - val_loss: 0.6479 - val_accuracy: 0.7025\n",
      "Epoch 362/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7043 - val_loss: 0.6513 - val_accuracy: 0.6867\n",
      "Epoch 363/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7029 - val_loss: 0.6464 - val_accuracy: 0.6930\n",
      "Epoch 364/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.6994 - val_loss: 0.6492 - val_accuracy: 0.7025\n",
      "Epoch 365/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7022 - val_loss: 0.6473 - val_accuracy: 0.6899\n",
      "Epoch 366/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7025 - val_loss: 0.6454 - val_accuracy: 0.6899\n",
      "Epoch 367/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7008 - val_loss: 0.6489 - val_accuracy: 0.6962\n",
      "Epoch 368/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7022 - val_loss: 0.6449 - val_accuracy: 0.6867\n",
      "Epoch 369/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7053 - val_loss: 0.6475 - val_accuracy: 0.6930\n",
      "Epoch 370/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7022 - val_loss: 0.6488 - val_accuracy: 0.7025\n",
      "Epoch 371/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7018 - val_loss: 0.6535 - val_accuracy: 0.6962\n",
      "Epoch 372/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7022 - val_loss: 0.6473 - val_accuracy: 0.6962\n",
      "Epoch 373/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.6997 - val_loss: 0.6509 - val_accuracy: 0.6994\n",
      "Epoch 374/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7043 - val_loss: 0.6490 - val_accuracy: 0.6994\n",
      "Epoch 375/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7050 - val_loss: 0.6479 - val_accuracy: 0.6930\n",
      "Epoch 376/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7099 - val_loss: 0.6523 - val_accuracy: 0.7025\n",
      "Epoch 377/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7032 - val_loss: 0.6488 - val_accuracy: 0.6962\n",
      "Epoch 378/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7078 - val_loss: 0.6498 - val_accuracy: 0.6994\n",
      "Epoch 379/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7029 - val_loss: 0.6519 - val_accuracy: 0.6994\n",
      "Epoch 380/1000\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.6983 - val_loss: 0.6510 - val_accuracy: 0.6962\n",
      "Epoch 381/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7032 - val_loss: 0.6492 - val_accuracy: 0.6930\n",
      "Epoch 382/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7110 - val_loss: 0.6527 - val_accuracy: 0.6962\n",
      "Epoch 383/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7039 - val_loss: 0.6567 - val_accuracy: 0.6994\n",
      "Epoch 384/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7015 - val_loss: 0.6535 - val_accuracy: 0.6962\n",
      "Epoch 385/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7039 - val_loss: 0.6480 - val_accuracy: 0.6835\n",
      "Epoch 386/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7018 - val_loss: 0.6527 - val_accuracy: 0.6930\n",
      "Epoch 387/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.6983 - val_loss: 0.6511 - val_accuracy: 0.6962\n",
      "Epoch 388/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.6976 - val_loss: 0.6485 - val_accuracy: 0.6930\n",
      "Epoch 389/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7071 - val_loss: 0.6515 - val_accuracy: 0.6994\n",
      "Epoch 390/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7120 - val_loss: 0.6614 - val_accuracy: 0.6804\n",
      "Epoch 391/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.6955 - val_loss: 0.6490 - val_accuracy: 0.6646\n",
      "Epoch 392/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7043 - val_loss: 0.6524 - val_accuracy: 0.6930\n",
      "Epoch 393/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7046 - val_loss: 0.6511 - val_accuracy: 0.6867\n",
      "Epoch 394/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7046 - val_loss: 0.6500 - val_accuracy: 0.6962\n",
      "Epoch 395/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7036 - val_loss: 0.6522 - val_accuracy: 0.6930\n",
      "Epoch 396/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7029 - val_loss: 0.6503 - val_accuracy: 0.6994\n",
      "Epoch 397/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7110 - val_loss: 0.6497 - val_accuracy: 0.6804\n",
      "Epoch 398/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7050 - val_loss: 0.6508 - val_accuracy: 0.6867\n",
      "Epoch 399/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.6997 - val_loss: 0.6496 - val_accuracy: 0.6709\n",
      "Epoch 400/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7089 - val_loss: 0.6492 - val_accuracy: 0.6804\n",
      "Epoch 401/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7096 - val_loss: 0.6503 - val_accuracy: 0.6804\n",
      "Epoch 402/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7053 - val_loss: 0.6483 - val_accuracy: 0.6772\n",
      "Epoch 403/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7057 - val_loss: 0.6515 - val_accuracy: 0.6899\n",
      "Epoch 404/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7096 - val_loss: 0.6484 - val_accuracy: 0.6772\n",
      "Epoch 405/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.7152 - val_loss: 0.6545 - val_accuracy: 0.6962\n",
      "Epoch 406/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7039 - val_loss: 0.6519 - val_accuracy: 0.6867\n",
      "Epoch 407/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7064 - val_loss: 0.6547 - val_accuracy: 0.6835\n",
      "Epoch 408/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7046 - val_loss: 0.6532 - val_accuracy: 0.6962\n",
      "Epoch 409/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7085 - val_loss: 0.6523 - val_accuracy: 0.6994\n",
      "Epoch 410/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7085 - val_loss: 0.6507 - val_accuracy: 0.6867\n",
      "Epoch 411/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7071 - val_loss: 0.6542 - val_accuracy: 0.6930\n",
      "Epoch 412/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7022 - val_loss: 0.6501 - val_accuracy: 0.6930\n",
      "Epoch 413/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7082 - val_loss: 0.6513 - val_accuracy: 0.7025\n",
      "Epoch 414/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7018 - val_loss: 0.6515 - val_accuracy: 0.6899\n",
      "Epoch 415/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7025 - val_loss: 0.6522 - val_accuracy: 0.6899\n",
      "Epoch 416/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7004 - val_loss: 0.6517 - val_accuracy: 0.6835\n",
      "Epoch 417/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7089 - val_loss: 0.6507 - val_accuracy: 0.6835\n",
      "Epoch 418/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7085 - val_loss: 0.6541 - val_accuracy: 0.6899\n",
      "Epoch 419/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7043 - val_loss: 0.6523 - val_accuracy: 0.6835\n",
      "Epoch 420/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7117 - val_loss: 0.6537 - val_accuracy: 0.6962\n",
      "Epoch 421/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7050 - val_loss: 0.6523 - val_accuracy: 0.7025\n",
      "Epoch 422/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7068 - val_loss: 0.6467 - val_accuracy: 0.6741\n",
      "Epoch 423/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7050 - val_loss: 0.6488 - val_accuracy: 0.6867\n",
      "Epoch 424/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.7082 - val_loss: 0.6531 - val_accuracy: 0.6867\n",
      "Epoch 425/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7039 - val_loss: 0.6480 - val_accuracy: 0.6741\n",
      "Epoch 426/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7103 - val_loss: 0.6506 - val_accuracy: 0.6994\n",
      "Epoch 427/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7110 - val_loss: 0.6485 - val_accuracy: 0.6930\n",
      "Epoch 428/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7064 - val_loss: 0.6478 - val_accuracy: 0.6930\n",
      "Epoch 429/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7068 - val_loss: 0.6462 - val_accuracy: 0.6930\n",
      "Epoch 430/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7022 - val_loss: 0.6500 - val_accuracy: 0.6962\n",
      "Epoch 431/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.6976 - val_loss: 0.6495 - val_accuracy: 0.6962\n",
      "Epoch 432/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7068 - val_loss: 0.6514 - val_accuracy: 0.6930\n",
      "Epoch 433/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7032 - val_loss: 0.6513 - val_accuracy: 0.6930\n",
      "Epoch 434/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7117 - val_loss: 0.6482 - val_accuracy: 0.6835\n",
      "Epoch 435/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7110 - val_loss: 0.6517 - val_accuracy: 0.6867\n",
      "Epoch 436/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7089 - val_loss: 0.6508 - val_accuracy: 0.6899\n",
      "Epoch 437/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7068 - val_loss: 0.6495 - val_accuracy: 0.6899\n",
      "Epoch 438/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7039 - val_loss: 0.6504 - val_accuracy: 0.6930\n",
      "Epoch 439/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7053 - val_loss: 0.6554 - val_accuracy: 0.6930\n",
      "Epoch 440/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7036 - val_loss: 0.6567 - val_accuracy: 0.6962\n",
      "Epoch 441/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7068 - val_loss: 0.6539 - val_accuracy: 0.6930\n",
      "Epoch 442/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7039 - val_loss: 0.6493 - val_accuracy: 0.6962\n",
      "Epoch 443/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7015 - val_loss: 0.6499 - val_accuracy: 0.6930\n",
      "Epoch 444/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7050 - val_loss: 0.6576 - val_accuracy: 0.6962\n",
      "Epoch 445/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7064 - val_loss: 0.6489 - val_accuracy: 0.6899\n",
      "Epoch 446/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7110 - val_loss: 0.6538 - val_accuracy: 0.6930\n",
      "Epoch 447/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7022 - val_loss: 0.6535 - val_accuracy: 0.6867\n",
      "Epoch 448/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7022 - val_loss: 0.6553 - val_accuracy: 0.6899\n",
      "Epoch 449/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7046 - val_loss: 0.6527 - val_accuracy: 0.6867\n",
      "Epoch 450/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7096 - val_loss: 0.6530 - val_accuracy: 0.6994\n",
      "Epoch 451/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7064 - val_loss: 0.6543 - val_accuracy: 0.7025\n",
      "Epoch 452/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7018 - val_loss: 0.6509 - val_accuracy: 0.6804\n",
      "Epoch 453/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7099 - val_loss: 0.6526 - val_accuracy: 0.6962\n",
      "Epoch 454/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7071 - val_loss: 0.6509 - val_accuracy: 0.6835\n",
      "Epoch 455/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7085 - val_loss: 0.6532 - val_accuracy: 0.6835\n",
      "Epoch 456/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7117 - val_loss: 0.6561 - val_accuracy: 0.6899\n",
      "Epoch 457/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7082 - val_loss: 0.6546 - val_accuracy: 0.6962\n",
      "Epoch 458/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7043 - val_loss: 0.6512 - val_accuracy: 0.6962\n",
      "Epoch 459/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7078 - val_loss: 0.6531 - val_accuracy: 0.6962\n",
      "Epoch 460/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7089 - val_loss: 0.6525 - val_accuracy: 0.6867\n",
      "Epoch 461/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7064 - val_loss: 0.6523 - val_accuracy: 0.6962\n",
      "Epoch 462/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7145 - val_loss: 0.6515 - val_accuracy: 0.7025\n",
      "Epoch 463/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7078 - val_loss: 0.6566 - val_accuracy: 0.7057\n",
      "Epoch 464/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7096 - val_loss: 0.6514 - val_accuracy: 0.6899\n",
      "Epoch 465/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7053 - val_loss: 0.6517 - val_accuracy: 0.6867\n",
      "Epoch 466/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.6997 - val_loss: 0.6499 - val_accuracy: 0.6930\n",
      "Epoch 467/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7068 - val_loss: 0.6527 - val_accuracy: 0.6930\n",
      "Epoch 468/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7075 - val_loss: 0.6538 - val_accuracy: 0.7025\n",
      "Epoch 469/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7092 - val_loss: 0.6562 - val_accuracy: 0.6835\n",
      "Epoch 470/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7060 - val_loss: 0.6521 - val_accuracy: 0.6930\n",
      "Epoch 471/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7117 - val_loss: 0.6502 - val_accuracy: 0.6835\n",
      "Epoch 472/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7110 - val_loss: 0.6553 - val_accuracy: 0.6930\n",
      "Epoch 473/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7082 - val_loss: 0.6530 - val_accuracy: 0.6930\n",
      "Epoch 474/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7078 - val_loss: 0.6543 - val_accuracy: 0.6994\n",
      "Epoch 475/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7092 - val_loss: 0.6559 - val_accuracy: 0.6804\n",
      "Epoch 476/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7043 - val_loss: 0.6565 - val_accuracy: 0.6867\n",
      "Epoch 477/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7085 - val_loss: 0.6534 - val_accuracy: 0.6899\n",
      "Epoch 478/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7025 - val_loss: 0.6550 - val_accuracy: 0.6804\n",
      "Epoch 479/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7057 - val_loss: 0.6537 - val_accuracy: 0.6930\n",
      "Epoch 480/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7071 - val_loss: 0.6513 - val_accuracy: 0.6899\n",
      "Epoch 481/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7145 - val_loss: 0.6522 - val_accuracy: 0.6899\n",
      "Epoch 482/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7050 - val_loss: 0.6527 - val_accuracy: 0.6994\n",
      "Epoch 483/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7096 - val_loss: 0.6468 - val_accuracy: 0.6962\n",
      "Epoch 484/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7078 - val_loss: 0.6496 - val_accuracy: 0.6962\n",
      "Epoch 485/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7078 - val_loss: 0.6483 - val_accuracy: 0.6930\n",
      "Epoch 486/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7096 - val_loss: 0.6479 - val_accuracy: 0.6899\n",
      "Epoch 487/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7060 - val_loss: 0.6465 - val_accuracy: 0.6899\n",
      "Epoch 488/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7050 - val_loss: 0.6522 - val_accuracy: 0.6899\n",
      "Epoch 489/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7092 - val_loss: 0.6486 - val_accuracy: 0.6867\n",
      "Epoch 490/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7120 - val_loss: 0.6510 - val_accuracy: 0.6930\n",
      "Epoch 491/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7106 - val_loss: 0.6488 - val_accuracy: 0.6804\n",
      "Epoch 492/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7099 - val_loss: 0.6499 - val_accuracy: 0.6930\n",
      "Epoch 493/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7138 - val_loss: 0.6464 - val_accuracy: 0.6930\n",
      "Epoch 494/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7082 - val_loss: 0.6513 - val_accuracy: 0.6994\n",
      "Epoch 495/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7039 - val_loss: 0.6478 - val_accuracy: 0.6899\n",
      "Epoch 496/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7078 - val_loss: 0.6501 - val_accuracy: 0.6867\n",
      "Epoch 497/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7053 - val_loss: 0.6531 - val_accuracy: 0.6962\n",
      "Epoch 498/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7060 - val_loss: 0.6521 - val_accuracy: 0.6994\n",
      "Epoch 499/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7082 - val_loss: 0.6543 - val_accuracy: 0.6930\n",
      "Epoch 500/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7050 - val_loss: 0.6534 - val_accuracy: 0.6899\n",
      "Epoch 501/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7162 - val_loss: 0.6569 - val_accuracy: 0.6930\n",
      "Epoch 502/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7106 - val_loss: 0.6558 - val_accuracy: 0.7025\n",
      "Epoch 503/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7071 - val_loss: 0.6488 - val_accuracy: 0.6867\n",
      "Epoch 504/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7092 - val_loss: 0.6498 - val_accuracy: 0.6930\n",
      "Epoch 505/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7124 - val_loss: 0.6552 - val_accuracy: 0.6994\n",
      "Epoch 506/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7008 - val_loss: 0.6506 - val_accuracy: 0.6867\n",
      "Epoch 507/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7092 - val_loss: 0.6483 - val_accuracy: 0.6962\n",
      "Epoch 508/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5623 - accuracy: 0.7117 - val_loss: 0.6522 - val_accuracy: 0.6835\n",
      "Epoch 509/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7057 - val_loss: 0.6565 - val_accuracy: 0.6835\n",
      "Epoch 510/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7092 - val_loss: 0.6509 - val_accuracy: 0.6899\n",
      "Epoch 511/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7085 - val_loss: 0.6542 - val_accuracy: 0.6930\n",
      "Epoch 512/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.7092 - val_loss: 0.6519 - val_accuracy: 0.6930\n",
      "Epoch 513/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7082 - val_loss: 0.6516 - val_accuracy: 0.6899\n",
      "Epoch 514/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7050 - val_loss: 0.6508 - val_accuracy: 0.6930\n",
      "Epoch 515/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7099 - val_loss: 0.6520 - val_accuracy: 0.6930\n",
      "Epoch 516/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7085 - val_loss: 0.6516 - val_accuracy: 0.6867\n",
      "Epoch 517/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7110 - val_loss: 0.6497 - val_accuracy: 0.6899\n",
      "Epoch 518/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7089 - val_loss: 0.6557 - val_accuracy: 0.6867\n",
      "Epoch 519/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7106 - val_loss: 0.6537 - val_accuracy: 0.6899\n",
      "Epoch 520/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7053 - val_loss: 0.6537 - val_accuracy: 0.6835\n",
      "Epoch 521/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7099 - val_loss: 0.6624 - val_accuracy: 0.7057\n",
      "Epoch 522/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7075 - val_loss: 0.6549 - val_accuracy: 0.6804\n",
      "Epoch 523/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7075 - val_loss: 0.6521 - val_accuracy: 0.6835\n",
      "Epoch 524/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7036 - val_loss: 0.6533 - val_accuracy: 0.6899\n",
      "Epoch 525/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7082 - val_loss: 0.6567 - val_accuracy: 0.6899\n",
      "Epoch 526/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7075 - val_loss: 0.6537 - val_accuracy: 0.6835\n",
      "Epoch 527/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.7103 - val_loss: 0.6524 - val_accuracy: 0.6867\n",
      "Epoch 528/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7120 - val_loss: 0.6590 - val_accuracy: 0.6899\n",
      "Epoch 529/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7078 - val_loss: 0.6525 - val_accuracy: 0.6835\n",
      "Epoch 530/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5658 - accuracy: 0.7075 - val_loss: 0.6562 - val_accuracy: 0.6835\n",
      "Epoch 531/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7036 - val_loss: 0.6545 - val_accuracy: 0.6899\n",
      "Epoch 532/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7106 - val_loss: 0.6523 - val_accuracy: 0.6867\n",
      "Epoch 533/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7124 - val_loss: 0.6534 - val_accuracy: 0.6899\n",
      "Epoch 534/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7060 - val_loss: 0.6541 - val_accuracy: 0.6867\n",
      "Epoch 535/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7131 - val_loss: 0.6548 - val_accuracy: 0.6867\n",
      "Epoch 536/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7099 - val_loss: 0.6548 - val_accuracy: 0.6899\n",
      "Epoch 537/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7110 - val_loss: 0.6557 - val_accuracy: 0.6930\n",
      "Epoch 538/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7159 - val_loss: 0.6571 - val_accuracy: 0.6899\n",
      "Epoch 539/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7064 - val_loss: 0.6556 - val_accuracy: 0.6962\n",
      "Epoch 540/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7018 - val_loss: 0.6564 - val_accuracy: 0.6835\n",
      "Epoch 541/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7106 - val_loss: 0.6562 - val_accuracy: 0.6930\n",
      "Epoch 542/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7089 - val_loss: 0.6552 - val_accuracy: 0.6867\n",
      "Epoch 543/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7071 - val_loss: 0.6550 - val_accuracy: 0.6899\n",
      "Epoch 544/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7096 - val_loss: 0.6490 - val_accuracy: 0.6772\n",
      "Epoch 545/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7092 - val_loss: 0.6567 - val_accuracy: 0.6899\n",
      "Epoch 546/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7113 - val_loss: 0.6537 - val_accuracy: 0.6867\n",
      "Epoch 547/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7092 - val_loss: 0.6511 - val_accuracy: 0.6867\n",
      "Epoch 548/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7060 - val_loss: 0.6533 - val_accuracy: 0.6835\n",
      "Epoch 549/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7131 - val_loss: 0.6572 - val_accuracy: 0.6899\n",
      "Epoch 550/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7124 - val_loss: 0.6547 - val_accuracy: 0.6835\n",
      "Epoch 551/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7078 - val_loss: 0.6603 - val_accuracy: 0.6930\n",
      "Epoch 552/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7089 - val_loss: 0.6551 - val_accuracy: 0.6899\n",
      "Epoch 553/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7169 - val_loss: 0.6602 - val_accuracy: 0.6867\n",
      "Epoch 554/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7103 - val_loss: 0.6600 - val_accuracy: 0.6962\n",
      "Epoch 555/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.7106 - val_loss: 0.6597 - val_accuracy: 0.6899\n",
      "Epoch 556/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7082 - val_loss: 0.6600 - val_accuracy: 0.6899\n",
      "Epoch 557/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7099 - val_loss: 0.6570 - val_accuracy: 0.6899\n",
      "Epoch 558/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7089 - val_loss: 0.6571 - val_accuracy: 0.6867\n",
      "Epoch 559/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7134 - val_loss: 0.6579 - val_accuracy: 0.6867\n",
      "Epoch 560/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7127 - val_loss: 0.6595 - val_accuracy: 0.6930\n",
      "Epoch 561/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7145 - val_loss: 0.6534 - val_accuracy: 0.6867\n",
      "Epoch 562/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7103 - val_loss: 0.6567 - val_accuracy: 0.6962\n",
      "Epoch 563/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7071 - val_loss: 0.6551 - val_accuracy: 0.6867\n",
      "Epoch 564/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7110 - val_loss: 0.6547 - val_accuracy: 0.6899\n",
      "Epoch 565/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7089 - val_loss: 0.6536 - val_accuracy: 0.6867\n",
      "Epoch 566/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7071 - val_loss: 0.6527 - val_accuracy: 0.6867\n",
      "Epoch 567/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7141 - val_loss: 0.6556 - val_accuracy: 0.6899\n",
      "Epoch 568/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7162 - val_loss: 0.6561 - val_accuracy: 0.6899\n",
      "Epoch 569/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7145 - val_loss: 0.6546 - val_accuracy: 0.6930\n",
      "Epoch 570/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7117 - val_loss: 0.6566 - val_accuracy: 0.6867\n",
      "Epoch 571/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7131 - val_loss: 0.6616 - val_accuracy: 0.6867\n",
      "Epoch 572/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7134 - val_loss: 0.6607 - val_accuracy: 0.6835\n",
      "Epoch 573/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7099 - val_loss: 0.6607 - val_accuracy: 0.6835\n",
      "Epoch 574/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7078 - val_loss: 0.6612 - val_accuracy: 0.6867\n",
      "Epoch 575/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7075 - val_loss: 0.6600 - val_accuracy: 0.6804\n",
      "Epoch 576/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7103 - val_loss: 0.6619 - val_accuracy: 0.6804\n",
      "Epoch 577/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.7089 - val_loss: 0.6577 - val_accuracy: 0.6899\n",
      "Epoch 578/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7106 - val_loss: 0.6596 - val_accuracy: 0.6899\n",
      "Epoch 579/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7085 - val_loss: 0.6585 - val_accuracy: 0.6835\n",
      "Epoch 580/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7096 - val_loss: 0.6584 - val_accuracy: 0.6867\n",
      "Epoch 581/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.7106 - val_loss: 0.6594 - val_accuracy: 0.6804\n",
      "Epoch 582/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7096 - val_loss: 0.6606 - val_accuracy: 0.6804\n",
      "Epoch 583/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7110 - val_loss: 0.6567 - val_accuracy: 0.6741\n",
      "Epoch 584/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7089 - val_loss: 0.6598 - val_accuracy: 0.6709\n",
      "Epoch 585/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7131 - val_loss: 0.6598 - val_accuracy: 0.6962\n",
      "Epoch 586/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7166 - val_loss: 0.6616 - val_accuracy: 0.6867\n",
      "Epoch 587/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7162 - val_loss: 0.6616 - val_accuracy: 0.6804\n",
      "Epoch 588/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7124 - val_loss: 0.6620 - val_accuracy: 0.6835\n",
      "Epoch 589/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7159 - val_loss: 0.6581 - val_accuracy: 0.6867\n",
      "Epoch 590/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7187 - val_loss: 0.6622 - val_accuracy: 0.6709\n",
      "Epoch 591/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7089 - val_loss: 0.6589 - val_accuracy: 0.6962\n",
      "Epoch 592/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7057 - val_loss: 0.6606 - val_accuracy: 0.6804\n",
      "Epoch 593/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7131 - val_loss: 0.6592 - val_accuracy: 0.6772\n",
      "Epoch 594/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7106 - val_loss: 0.6634 - val_accuracy: 0.6867\n",
      "Epoch 595/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7096 - val_loss: 0.6571 - val_accuracy: 0.6899\n",
      "Epoch 596/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7120 - val_loss: 0.6580 - val_accuracy: 0.6804\n",
      "Epoch 597/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7110 - val_loss: 0.6596 - val_accuracy: 0.6772\n",
      "Epoch 598/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7117 - val_loss: 0.6660 - val_accuracy: 0.6930\n",
      "Epoch 599/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7085 - val_loss: 0.6621 - val_accuracy: 0.6899\n",
      "Epoch 600/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7127 - val_loss: 0.6614 - val_accuracy: 0.6804\n",
      "Epoch 601/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7103 - val_loss: 0.6597 - val_accuracy: 0.6962\n",
      "Epoch 602/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7053 - val_loss: 0.6604 - val_accuracy: 0.6899\n",
      "Epoch 603/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7057 - val_loss: 0.6625 - val_accuracy: 0.6867\n",
      "Epoch 604/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7131 - val_loss: 0.6606 - val_accuracy: 0.6867\n",
      "Epoch 605/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7071 - val_loss: 0.6627 - val_accuracy: 0.6899\n",
      "Epoch 606/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7205 - val_loss: 0.6584 - val_accuracy: 0.6899\n",
      "Epoch 607/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7134 - val_loss: 0.6528 - val_accuracy: 0.6709\n",
      "Epoch 608/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7134 - val_loss: 0.6598 - val_accuracy: 0.6867\n",
      "Epoch 609/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7155 - val_loss: 0.6627 - val_accuracy: 0.6804\n",
      "Epoch 610/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7068 - val_loss: 0.6587 - val_accuracy: 0.6962\n",
      "Epoch 611/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7127 - val_loss: 0.6620 - val_accuracy: 0.6962\n",
      "Epoch 612/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7117 - val_loss: 0.6611 - val_accuracy: 0.6835\n",
      "Epoch 613/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7124 - val_loss: 0.6589 - val_accuracy: 0.6867\n",
      "Epoch 614/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7127 - val_loss: 0.6591 - val_accuracy: 0.6835\n",
      "Epoch 615/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7127 - val_loss: 0.6617 - val_accuracy: 0.6962\n",
      "Epoch 616/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7162 - val_loss: 0.6590 - val_accuracy: 0.6772\n",
      "Epoch 617/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7127 - val_loss: 0.6619 - val_accuracy: 0.6899\n",
      "Epoch 618/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7089 - val_loss: 0.6621 - val_accuracy: 0.6867\n",
      "Epoch 619/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7152 - val_loss: 0.6598 - val_accuracy: 0.6835\n",
      "Epoch 620/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7099 - val_loss: 0.6626 - val_accuracy: 0.6772\n",
      "Epoch 621/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7085 - val_loss: 0.6623 - val_accuracy: 0.6867\n",
      "Epoch 622/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7089 - val_loss: 0.6617 - val_accuracy: 0.6899\n",
      "Epoch 623/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7162 - val_loss: 0.6612 - val_accuracy: 0.6835\n",
      "Epoch 624/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7145 - val_loss: 0.6598 - val_accuracy: 0.6804\n",
      "Epoch 625/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7117 - val_loss: 0.6669 - val_accuracy: 0.6804\n",
      "Epoch 626/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7141 - val_loss: 0.6629 - val_accuracy: 0.6899\n",
      "Epoch 627/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7099 - val_loss: 0.6620 - val_accuracy: 0.6899\n",
      "Epoch 628/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7173 - val_loss: 0.6630 - val_accuracy: 0.6962\n",
      "Epoch 629/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7120 - val_loss: 0.6625 - val_accuracy: 0.6899\n",
      "Epoch 630/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7075 - val_loss: 0.6596 - val_accuracy: 0.6962\n",
      "Epoch 631/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7155 - val_loss: 0.6583 - val_accuracy: 0.6772\n",
      "Epoch 632/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7117 - val_loss: 0.6574 - val_accuracy: 0.6867\n",
      "Epoch 633/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7162 - val_loss: 0.6623 - val_accuracy: 0.6804\n",
      "Epoch 634/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7134 - val_loss: 0.6603 - val_accuracy: 0.6930\n",
      "Epoch 635/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7060 - val_loss: 0.6602 - val_accuracy: 0.6867\n",
      "Epoch 636/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7148 - val_loss: 0.6589 - val_accuracy: 0.6835\n",
      "Epoch 637/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7127 - val_loss: 0.6607 - val_accuracy: 0.6804\n",
      "Epoch 638/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7113 - val_loss: 0.6624 - val_accuracy: 0.6804\n",
      "Epoch 639/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7169 - val_loss: 0.6652 - val_accuracy: 0.6804\n",
      "Epoch 640/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7141 - val_loss: 0.6661 - val_accuracy: 0.6835\n",
      "Epoch 641/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7134 - val_loss: 0.6629 - val_accuracy: 0.6835\n",
      "Epoch 642/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7155 - val_loss: 0.6640 - val_accuracy: 0.6804\n",
      "Epoch 643/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7145 - val_loss: 0.6618 - val_accuracy: 0.6899\n",
      "Epoch 644/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7134 - val_loss: 0.6639 - val_accuracy: 0.6835\n",
      "Epoch 645/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7141 - val_loss: 0.6622 - val_accuracy: 0.6804\n",
      "Epoch 646/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7106 - val_loss: 0.6630 - val_accuracy: 0.6930\n",
      "Epoch 647/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7177 - val_loss: 0.6640 - val_accuracy: 0.6835\n",
      "Epoch 648/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7120 - val_loss: 0.6654 - val_accuracy: 0.6835\n",
      "Epoch 649/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7159 - val_loss: 0.6647 - val_accuracy: 0.6867\n",
      "Epoch 650/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7117 - val_loss: 0.6673 - val_accuracy: 0.6835\n",
      "Epoch 651/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7120 - val_loss: 0.6679 - val_accuracy: 0.6772\n",
      "Epoch 652/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7120 - val_loss: 0.6664 - val_accuracy: 0.6899\n",
      "Epoch 653/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7194 - val_loss: 0.6659 - val_accuracy: 0.6772\n",
      "Epoch 654/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7124 - val_loss: 0.6625 - val_accuracy: 0.6804\n",
      "Epoch 655/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7162 - val_loss: 0.6658 - val_accuracy: 0.6867\n",
      "Epoch 656/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7145 - val_loss: 0.6674 - val_accuracy: 0.6867\n",
      "Epoch 657/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7152 - val_loss: 0.6649 - val_accuracy: 0.6835\n",
      "Epoch 658/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7134 - val_loss: 0.6673 - val_accuracy: 0.6930\n",
      "Epoch 659/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7180 - val_loss: 0.6640 - val_accuracy: 0.6804\n",
      "Epoch 660/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7120 - val_loss: 0.6654 - val_accuracy: 0.6835\n",
      "Epoch 661/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7141 - val_loss: 0.6637 - val_accuracy: 0.6772\n",
      "Epoch 662/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7180 - val_loss: 0.6656 - val_accuracy: 0.6867\n",
      "Epoch 663/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7162 - val_loss: 0.6668 - val_accuracy: 0.6741\n",
      "Epoch 664/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7117 - val_loss: 0.6620 - val_accuracy: 0.6867\n",
      "Epoch 665/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7131 - val_loss: 0.6670 - val_accuracy: 0.6804\n",
      "Epoch 666/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7180 - val_loss: 0.6654 - val_accuracy: 0.6835\n",
      "Epoch 667/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7078 - val_loss: 0.6646 - val_accuracy: 0.6772\n",
      "Epoch 668/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7138 - val_loss: 0.6660 - val_accuracy: 0.6835\n",
      "Epoch 669/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7236 - val_loss: 0.6683 - val_accuracy: 0.6867\n",
      "Epoch 670/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7145 - val_loss: 0.6699 - val_accuracy: 0.6772\n",
      "Epoch 671/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7106 - val_loss: 0.6636 - val_accuracy: 0.6867\n",
      "Epoch 672/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7155 - val_loss: 0.6674 - val_accuracy: 0.6741\n",
      "Epoch 673/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7138 - val_loss: 0.6686 - val_accuracy: 0.6804\n",
      "Epoch 674/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7173 - val_loss: 0.6692 - val_accuracy: 0.6899\n",
      "Epoch 675/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7134 - val_loss: 0.6696 - val_accuracy: 0.6772\n",
      "Epoch 676/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7166 - val_loss: 0.6727 - val_accuracy: 0.6867\n",
      "Epoch 677/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7148 - val_loss: 0.6688 - val_accuracy: 0.6899\n",
      "Epoch 678/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7138 - val_loss: 0.6708 - val_accuracy: 0.6930\n",
      "Epoch 679/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7194 - val_loss: 0.6738 - val_accuracy: 0.6772\n",
      "Epoch 680/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7180 - val_loss: 0.6685 - val_accuracy: 0.6835\n",
      "Epoch 681/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7159 - val_loss: 0.6722 - val_accuracy: 0.6709\n",
      "Epoch 682/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7057 - val_loss: 0.6722 - val_accuracy: 0.6709\n",
      "Epoch 683/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7152 - val_loss: 0.6630 - val_accuracy: 0.6867\n",
      "Epoch 684/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7155 - val_loss: 0.6659 - val_accuracy: 0.6835\n",
      "Epoch 685/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7180 - val_loss: 0.6660 - val_accuracy: 0.6835\n",
      "Epoch 686/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7127 - val_loss: 0.6635 - val_accuracy: 0.6804\n",
      "Epoch 687/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.7166 - val_loss: 0.6636 - val_accuracy: 0.6772\n",
      "Epoch 688/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7134 - val_loss: 0.6623 - val_accuracy: 0.6899\n",
      "Epoch 689/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7103 - val_loss: 0.6643 - val_accuracy: 0.6867\n",
      "Epoch 690/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7159 - val_loss: 0.6663 - val_accuracy: 0.6867\n",
      "Epoch 691/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7208 - val_loss: 0.6726 - val_accuracy: 0.6930\n",
      "Epoch 692/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7120 - val_loss: 0.6681 - val_accuracy: 0.6835\n",
      "Epoch 693/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7187 - val_loss: 0.6715 - val_accuracy: 0.6804\n",
      "Epoch 694/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7117 - val_loss: 0.6663 - val_accuracy: 0.6899\n",
      "Epoch 695/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7159 - val_loss: 0.6691 - val_accuracy: 0.6867\n",
      "Epoch 696/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7131 - val_loss: 0.6679 - val_accuracy: 0.6772\n",
      "Epoch 697/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7131 - val_loss: 0.6710 - val_accuracy: 0.6772\n",
      "Epoch 698/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7138 - val_loss: 0.6673 - val_accuracy: 0.6772\n",
      "Epoch 699/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.7138 - val_loss: 0.6680 - val_accuracy: 0.6867\n",
      "Epoch 700/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7120 - val_loss: 0.6634 - val_accuracy: 0.6835\n",
      "Epoch 701/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7120 - val_loss: 0.6645 - val_accuracy: 0.6804\n",
      "Epoch 702/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7162 - val_loss: 0.6663 - val_accuracy: 0.6835\n",
      "Epoch 703/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7194 - val_loss: 0.6701 - val_accuracy: 0.6772\n",
      "Epoch 704/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7127 - val_loss: 0.6710 - val_accuracy: 0.6677\n",
      "Epoch 705/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7215 - val_loss: 0.6707 - val_accuracy: 0.6804\n",
      "Epoch 706/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7162 - val_loss: 0.6694 - val_accuracy: 0.6804\n",
      "Epoch 707/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7068 - val_loss: 0.6674 - val_accuracy: 0.6804\n",
      "Epoch 708/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7173 - val_loss: 0.6695 - val_accuracy: 0.6772\n",
      "Epoch 709/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7173 - val_loss: 0.6741 - val_accuracy: 0.6804\n",
      "Epoch 710/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7138 - val_loss: 0.6703 - val_accuracy: 0.6867\n",
      "Epoch 711/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7166 - val_loss: 0.6714 - val_accuracy: 0.6804\n",
      "Epoch 712/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7191 - val_loss: 0.6704 - val_accuracy: 0.6804\n",
      "Epoch 713/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7173 - val_loss: 0.6698 - val_accuracy: 0.6772\n",
      "Epoch 714/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7141 - val_loss: 0.6733 - val_accuracy: 0.6741\n",
      "Epoch 715/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7198 - val_loss: 0.6731 - val_accuracy: 0.6741\n",
      "Epoch 716/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7166 - val_loss: 0.6710 - val_accuracy: 0.6772\n",
      "Epoch 717/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7198 - val_loss: 0.6715 - val_accuracy: 0.6867\n",
      "Epoch 718/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7166 - val_loss: 0.6706 - val_accuracy: 0.6867\n",
      "Epoch 719/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7162 - val_loss: 0.6698 - val_accuracy: 0.6804\n",
      "Epoch 720/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7117 - val_loss: 0.6705 - val_accuracy: 0.6899\n",
      "Epoch 721/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7191 - val_loss: 0.6716 - val_accuracy: 0.6962\n",
      "Epoch 722/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7177 - val_loss: 0.6736 - val_accuracy: 0.6867\n",
      "Epoch 723/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7184 - val_loss: 0.6722 - val_accuracy: 0.6867\n",
      "Epoch 724/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7159 - val_loss: 0.6759 - val_accuracy: 0.6804\n",
      "Epoch 725/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7219 - val_loss: 0.6726 - val_accuracy: 0.6804\n",
      "Epoch 726/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7205 - val_loss: 0.6716 - val_accuracy: 0.6709\n",
      "Epoch 727/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7169 - val_loss: 0.6684 - val_accuracy: 0.6899\n",
      "Epoch 728/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7208 - val_loss: 0.6711 - val_accuracy: 0.6804\n",
      "Epoch 729/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7085 - val_loss: 0.6723 - val_accuracy: 0.6772\n",
      "Epoch 730/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7173 - val_loss: 0.6714 - val_accuracy: 0.6835\n",
      "Epoch 731/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7131 - val_loss: 0.6665 - val_accuracy: 0.6867\n",
      "Epoch 732/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7208 - val_loss: 0.6713 - val_accuracy: 0.6867\n",
      "Epoch 733/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7162 - val_loss: 0.6707 - val_accuracy: 0.6867\n",
      "Epoch 734/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7233 - val_loss: 0.6717 - val_accuracy: 0.6804\n",
      "Epoch 735/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7194 - val_loss: 0.6732 - val_accuracy: 0.6646\n",
      "Epoch 736/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7180 - val_loss: 0.6732 - val_accuracy: 0.6899\n",
      "Epoch 737/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7103 - val_loss: 0.6741 - val_accuracy: 0.6835\n",
      "Epoch 738/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.7194 - val_loss: 0.6757 - val_accuracy: 0.6772\n",
      "Epoch 739/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7212 - val_loss: 0.6754 - val_accuracy: 0.6741\n",
      "Epoch 740/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7145 - val_loss: 0.6801 - val_accuracy: 0.6741\n",
      "Epoch 741/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7191 - val_loss: 0.6720 - val_accuracy: 0.6835\n",
      "Epoch 742/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7215 - val_loss: 0.6735 - val_accuracy: 0.6867\n",
      "Epoch 743/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7222 - val_loss: 0.6745 - val_accuracy: 0.6835\n",
      "Epoch 744/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7138 - val_loss: 0.6765 - val_accuracy: 0.6804\n",
      "Epoch 745/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7127 - val_loss: 0.6739 - val_accuracy: 0.6867\n",
      "Epoch 746/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7240 - val_loss: 0.6764 - val_accuracy: 0.6835\n",
      "Epoch 747/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7173 - val_loss: 0.6730 - val_accuracy: 0.6804\n",
      "Epoch 748/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7169 - val_loss: 0.6715 - val_accuracy: 0.6772\n",
      "Epoch 749/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7201 - val_loss: 0.6733 - val_accuracy: 0.6772\n",
      "Epoch 750/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7201 - val_loss: 0.6739 - val_accuracy: 0.6741\n",
      "Epoch 751/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7219 - val_loss: 0.6721 - val_accuracy: 0.6804\n",
      "Epoch 752/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7226 - val_loss: 0.6751 - val_accuracy: 0.6709\n",
      "Epoch 753/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7131 - val_loss: 0.6762 - val_accuracy: 0.6709\n",
      "Epoch 754/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7187 - val_loss: 0.6723 - val_accuracy: 0.6741\n",
      "Epoch 755/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7113 - val_loss: 0.6730 - val_accuracy: 0.6741\n",
      "Epoch 756/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7201 - val_loss: 0.6777 - val_accuracy: 0.6709\n",
      "Epoch 757/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7264 - val_loss: 0.6745 - val_accuracy: 0.6772\n",
      "Epoch 758/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7250 - val_loss: 0.6783 - val_accuracy: 0.6741\n",
      "Epoch 759/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7194 - val_loss: 0.6753 - val_accuracy: 0.6646\n",
      "Epoch 760/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7236 - val_loss: 0.6762 - val_accuracy: 0.6804\n",
      "Epoch 761/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7205 - val_loss: 0.6749 - val_accuracy: 0.6867\n",
      "Epoch 762/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7184 - val_loss: 0.6724 - val_accuracy: 0.6867\n",
      "Epoch 763/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7096 - val_loss: 0.6702 - val_accuracy: 0.6804\n",
      "Epoch 764/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7215 - val_loss: 0.6738 - val_accuracy: 0.6772\n",
      "Epoch 765/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7254 - val_loss: 0.6770 - val_accuracy: 0.6772\n",
      "Epoch 766/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7173 - val_loss: 0.6756 - val_accuracy: 0.6835\n",
      "Epoch 767/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7247 - val_loss: 0.6761 - val_accuracy: 0.6835\n",
      "Epoch 768/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7215 - val_loss: 0.6758 - val_accuracy: 0.6804\n",
      "Epoch 769/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7212 - val_loss: 0.6781 - val_accuracy: 0.6772\n",
      "Epoch 770/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7247 - val_loss: 0.6802 - val_accuracy: 0.6677\n",
      "Epoch 771/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7264 - val_loss: 0.6759 - val_accuracy: 0.6772\n",
      "Epoch 772/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7177 - val_loss: 0.6780 - val_accuracy: 0.6741\n",
      "Epoch 773/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7229 - val_loss: 0.6816 - val_accuracy: 0.6741\n",
      "Epoch 774/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7159 - val_loss: 0.6867 - val_accuracy: 0.6677\n",
      "Epoch 775/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7240 - val_loss: 0.6815 - val_accuracy: 0.6677\n",
      "Epoch 776/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7226 - val_loss: 0.6771 - val_accuracy: 0.6772\n",
      "Epoch 777/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7198 - val_loss: 0.6745 - val_accuracy: 0.6741\n",
      "Epoch 778/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7194 - val_loss: 0.6747 - val_accuracy: 0.6741\n",
      "Epoch 779/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7219 - val_loss: 0.6782 - val_accuracy: 0.6709\n",
      "Epoch 780/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7201 - val_loss: 0.6764 - val_accuracy: 0.6709\n",
      "Epoch 781/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7191 - val_loss: 0.6807 - val_accuracy: 0.6741\n",
      "Epoch 782/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.7247 - val_loss: 0.6809 - val_accuracy: 0.6614\n",
      "Epoch 783/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7184 - val_loss: 0.6792 - val_accuracy: 0.6804\n",
      "Epoch 784/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7173 - val_loss: 0.6806 - val_accuracy: 0.6772\n",
      "Epoch 785/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7278 - val_loss: 0.6795 - val_accuracy: 0.6709\n",
      "Epoch 786/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7180 - val_loss: 0.6776 - val_accuracy: 0.6677\n",
      "Epoch 787/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7212 - val_loss: 0.6824 - val_accuracy: 0.6709\n",
      "Epoch 788/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7254 - val_loss: 0.6800 - val_accuracy: 0.6709\n",
      "Epoch 789/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7173 - val_loss: 0.6810 - val_accuracy: 0.6772\n",
      "Epoch 790/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7180 - val_loss: 0.6811 - val_accuracy: 0.6804\n",
      "Epoch 791/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7205 - val_loss: 0.6789 - val_accuracy: 0.6772\n",
      "Epoch 792/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7233 - val_loss: 0.6873 - val_accuracy: 0.6646\n",
      "Epoch 793/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7226 - val_loss: 0.6795 - val_accuracy: 0.6709\n",
      "Epoch 794/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7205 - val_loss: 0.6803 - val_accuracy: 0.6772\n",
      "Epoch 795/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7138 - val_loss: 0.6801 - val_accuracy: 0.6709\n",
      "Epoch 796/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7141 - val_loss: 0.6851 - val_accuracy: 0.6709\n",
      "Epoch 797/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7177 - val_loss: 0.6843 - val_accuracy: 0.6646\n",
      "Epoch 798/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7166 - val_loss: 0.6791 - val_accuracy: 0.6741\n",
      "Epoch 799/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7278 - val_loss: 0.6810 - val_accuracy: 0.6804\n",
      "Epoch 800/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7173 - val_loss: 0.6824 - val_accuracy: 0.6741\n",
      "Epoch 801/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7226 - val_loss: 0.6848 - val_accuracy: 0.6614\n",
      "Epoch 802/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7159 - val_loss: 0.6819 - val_accuracy: 0.6582\n",
      "Epoch 803/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7219 - val_loss: 0.6869 - val_accuracy: 0.6772\n",
      "Epoch 804/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7222 - val_loss: 0.6850 - val_accuracy: 0.6646\n",
      "Epoch 805/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7264 - val_loss: 0.6847 - val_accuracy: 0.6772\n",
      "Epoch 806/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7194 - val_loss: 0.6843 - val_accuracy: 0.6804\n",
      "Epoch 807/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7271 - val_loss: 0.6847 - val_accuracy: 0.6709\n",
      "Epoch 808/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7205 - val_loss: 0.6837 - val_accuracy: 0.6614\n",
      "Epoch 809/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7201 - val_loss: 0.6813 - val_accuracy: 0.6741\n",
      "Epoch 810/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7208 - val_loss: 0.6835 - val_accuracy: 0.6709\n",
      "Epoch 811/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7240 - val_loss: 0.6867 - val_accuracy: 0.6646\n",
      "Epoch 812/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7264 - val_loss: 0.6908 - val_accuracy: 0.6614\n",
      "Epoch 813/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7208 - val_loss: 0.6856 - val_accuracy: 0.6677\n",
      "Epoch 814/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7222 - val_loss: 0.6895 - val_accuracy: 0.6741\n",
      "Epoch 815/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7208 - val_loss: 0.6851 - val_accuracy: 0.6677\n",
      "Epoch 816/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7201 - val_loss: 0.6842 - val_accuracy: 0.6646\n",
      "Epoch 817/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7215 - val_loss: 0.6887 - val_accuracy: 0.6709\n",
      "Epoch 818/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7198 - val_loss: 0.6851 - val_accuracy: 0.6677\n",
      "Epoch 819/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7233 - val_loss: 0.6812 - val_accuracy: 0.6677\n",
      "Epoch 820/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7282 - val_loss: 0.6864 - val_accuracy: 0.6741\n",
      "Epoch 821/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7187 - val_loss: 0.6851 - val_accuracy: 0.6614\n",
      "Epoch 822/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7212 - val_loss: 0.6878 - val_accuracy: 0.6677\n",
      "Epoch 823/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7243 - val_loss: 0.6897 - val_accuracy: 0.6614\n",
      "Epoch 824/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7208 - val_loss: 0.6909 - val_accuracy: 0.6582\n",
      "Epoch 825/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7180 - val_loss: 0.6888 - val_accuracy: 0.6646\n",
      "Epoch 826/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7187 - val_loss: 0.6895 - val_accuracy: 0.6614\n",
      "Epoch 827/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7180 - val_loss: 0.6911 - val_accuracy: 0.6677\n",
      "Epoch 828/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7215 - val_loss: 0.6845 - val_accuracy: 0.6646\n",
      "Epoch 829/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7205 - val_loss: 0.6894 - val_accuracy: 0.6677\n",
      "Epoch 830/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7226 - val_loss: 0.6923 - val_accuracy: 0.6677\n",
      "Epoch 831/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7191 - val_loss: 0.6897 - val_accuracy: 0.6614\n",
      "Epoch 832/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7205 - val_loss: 0.6937 - val_accuracy: 0.6646\n",
      "Epoch 833/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7191 - val_loss: 0.6856 - val_accuracy: 0.6709\n",
      "Epoch 834/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7289 - val_loss: 0.6889 - val_accuracy: 0.6709\n",
      "Epoch 835/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7229 - val_loss: 0.6923 - val_accuracy: 0.6741\n",
      "Epoch 836/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7243 - val_loss: 0.6884 - val_accuracy: 0.6646\n",
      "Epoch 837/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7289 - val_loss: 0.6960 - val_accuracy: 0.6582\n",
      "Epoch 838/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7296 - val_loss: 0.6888 - val_accuracy: 0.6677\n",
      "Epoch 839/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7229 - val_loss: 0.6951 - val_accuracy: 0.6614\n",
      "Epoch 840/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7187 - val_loss: 0.6921 - val_accuracy: 0.6551\n",
      "Epoch 841/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7233 - val_loss: 0.6915 - val_accuracy: 0.6709\n",
      "Epoch 842/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7212 - val_loss: 0.6925 - val_accuracy: 0.6677\n",
      "Epoch 843/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7215 - val_loss: 0.6874 - val_accuracy: 0.6677\n",
      "Epoch 844/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7212 - val_loss: 0.6880 - val_accuracy: 0.6772\n",
      "Epoch 845/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7191 - val_loss: 0.6876 - val_accuracy: 0.6614\n",
      "Epoch 846/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7261 - val_loss: 0.6908 - val_accuracy: 0.6677\n",
      "Epoch 847/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7180 - val_loss: 0.6894 - val_accuracy: 0.6614\n",
      "Epoch 848/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7275 - val_loss: 0.6881 - val_accuracy: 0.6741\n",
      "Epoch 849/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7243 - val_loss: 0.6853 - val_accuracy: 0.6677\n",
      "Epoch 850/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7229 - val_loss: 0.6875 - val_accuracy: 0.6646\n",
      "Epoch 851/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7212 - val_loss: 0.6872 - val_accuracy: 0.6551\n",
      "Epoch 852/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7208 - val_loss: 0.6931 - val_accuracy: 0.6551\n",
      "Epoch 853/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7261 - val_loss: 0.6917 - val_accuracy: 0.6646\n",
      "Epoch 854/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7191 - val_loss: 0.6887 - val_accuracy: 0.6741\n",
      "Epoch 855/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7243 - val_loss: 0.6902 - val_accuracy: 0.6614\n",
      "Epoch 856/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7278 - val_loss: 0.6931 - val_accuracy: 0.6646\n",
      "Epoch 857/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7300 - val_loss: 0.6969 - val_accuracy: 0.6614\n",
      "Epoch 858/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7243 - val_loss: 0.6952 - val_accuracy: 0.6551\n",
      "Epoch 859/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7226 - val_loss: 0.6924 - val_accuracy: 0.6551\n",
      "Epoch 860/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7300 - val_loss: 0.6929 - val_accuracy: 0.6582\n",
      "Epoch 861/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7250 - val_loss: 0.6923 - val_accuracy: 0.6582\n",
      "Epoch 862/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7264 - val_loss: 0.6942 - val_accuracy: 0.6582\n",
      "Epoch 863/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7243 - val_loss: 0.6903 - val_accuracy: 0.6677\n",
      "Epoch 864/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7310 - val_loss: 0.6948 - val_accuracy: 0.6582\n",
      "Epoch 865/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7229 - val_loss: 0.6967 - val_accuracy: 0.6614\n",
      "Epoch 866/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7278 - val_loss: 0.6963 - val_accuracy: 0.6582\n",
      "Epoch 867/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7243 - val_loss: 0.6911 - val_accuracy: 0.6677\n",
      "Epoch 868/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7314 - val_loss: 0.6965 - val_accuracy: 0.6646\n",
      "Epoch 869/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7314 - val_loss: 0.6944 - val_accuracy: 0.6772\n",
      "Epoch 870/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7226 - val_loss: 0.6949 - val_accuracy: 0.6709\n",
      "Epoch 871/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7250 - val_loss: 0.6940 - val_accuracy: 0.6677\n",
      "Epoch 872/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7215 - val_loss: 0.6917 - val_accuracy: 0.6709\n",
      "Epoch 873/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7184 - val_loss: 0.6919 - val_accuracy: 0.6677\n",
      "Epoch 874/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7317 - val_loss: 0.7000 - val_accuracy: 0.6741\n",
      "Epoch 875/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7250 - val_loss: 0.6960 - val_accuracy: 0.6677\n",
      "Epoch 876/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7194 - val_loss: 0.6937 - val_accuracy: 0.6646\n",
      "Epoch 877/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7233 - val_loss: 0.6948 - val_accuracy: 0.6677\n",
      "Epoch 878/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7226 - val_loss: 0.6935 - val_accuracy: 0.6772\n",
      "Epoch 879/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7247 - val_loss: 0.6923 - val_accuracy: 0.6709\n",
      "Epoch 880/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7278 - val_loss: 0.6940 - val_accuracy: 0.6804\n",
      "Epoch 881/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7257 - val_loss: 0.6933 - val_accuracy: 0.6741\n",
      "Epoch 882/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7222 - val_loss: 0.6926 - val_accuracy: 0.6677\n",
      "Epoch 883/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7275 - val_loss: 0.6930 - val_accuracy: 0.6741\n",
      "Epoch 884/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7191 - val_loss: 0.6968 - val_accuracy: 0.6646\n",
      "Epoch 885/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7289 - val_loss: 0.6950 - val_accuracy: 0.6582\n",
      "Epoch 886/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7215 - val_loss: 0.6911 - val_accuracy: 0.6741\n",
      "Epoch 887/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7236 - val_loss: 0.6948 - val_accuracy: 0.6677\n",
      "Epoch 888/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7240 - val_loss: 0.6920 - val_accuracy: 0.6646\n",
      "Epoch 889/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7201 - val_loss: 0.6901 - val_accuracy: 0.6646\n",
      "Epoch 890/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7240 - val_loss: 0.6886 - val_accuracy: 0.6772\n",
      "Epoch 891/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7233 - val_loss: 0.6952 - val_accuracy: 0.6677\n",
      "Epoch 892/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7254 - val_loss: 0.6922 - val_accuracy: 0.6741\n",
      "Epoch 893/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7317 - val_loss: 0.6944 - val_accuracy: 0.6804\n",
      "Epoch 894/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7296 - val_loss: 0.6949 - val_accuracy: 0.6804\n",
      "Epoch 895/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7271 - val_loss: 0.6984 - val_accuracy: 0.6646\n",
      "Epoch 896/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7296 - val_loss: 0.6971 - val_accuracy: 0.6709\n",
      "Epoch 897/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7215 - val_loss: 0.6964 - val_accuracy: 0.6677\n",
      "Epoch 898/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7271 - val_loss: 0.7000 - val_accuracy: 0.6646\n",
      "Epoch 899/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7317 - val_loss: 0.6966 - val_accuracy: 0.6741\n",
      "Epoch 900/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7187 - val_loss: 0.6976 - val_accuracy: 0.6646\n",
      "Epoch 901/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7271 - val_loss: 0.6944 - val_accuracy: 0.6741\n",
      "Epoch 902/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7321 - val_loss: 0.6958 - val_accuracy: 0.6709\n",
      "Epoch 903/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7261 - val_loss: 0.6939 - val_accuracy: 0.6772\n",
      "Epoch 904/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7233 - val_loss: 0.6997 - val_accuracy: 0.6614\n",
      "Epoch 905/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7222 - val_loss: 0.6983 - val_accuracy: 0.6677\n",
      "Epoch 906/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7254 - val_loss: 0.6984 - val_accuracy: 0.6646\n",
      "Epoch 907/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7293 - val_loss: 0.7002 - val_accuracy: 0.6709\n",
      "Epoch 908/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7271 - val_loss: 0.6998 - val_accuracy: 0.6646\n",
      "Epoch 909/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7257 - val_loss: 0.7002 - val_accuracy: 0.6772\n",
      "Epoch 910/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7250 - val_loss: 0.6935 - val_accuracy: 0.6741\n",
      "Epoch 911/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7257 - val_loss: 0.6987 - val_accuracy: 0.6646\n",
      "Epoch 912/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7300 - val_loss: 0.6997 - val_accuracy: 0.6614\n",
      "Epoch 913/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7215 - val_loss: 0.6920 - val_accuracy: 0.6772\n",
      "Epoch 914/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7250 - val_loss: 0.6911 - val_accuracy: 0.6741\n",
      "Epoch 915/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7300 - val_loss: 0.6945 - val_accuracy: 0.6804\n",
      "Epoch 916/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7300 - val_loss: 0.6959 - val_accuracy: 0.6677\n",
      "Epoch 917/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7233 - val_loss: 0.7007 - val_accuracy: 0.6741\n",
      "Epoch 918/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7247 - val_loss: 0.7033 - val_accuracy: 0.6677\n",
      "Epoch 919/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7268 - val_loss: 0.7064 - val_accuracy: 0.6519\n",
      "Epoch 920/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7261 - val_loss: 0.7038 - val_accuracy: 0.6741\n",
      "Epoch 921/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7345 - val_loss: 0.7069 - val_accuracy: 0.6646\n",
      "Epoch 922/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7289 - val_loss: 0.7003 - val_accuracy: 0.6677\n",
      "Epoch 923/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7240 - val_loss: 0.7025 - val_accuracy: 0.6677\n",
      "Epoch 924/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7300 - val_loss: 0.7041 - val_accuracy: 0.6677\n",
      "Epoch 925/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7243 - val_loss: 0.7041 - val_accuracy: 0.6677\n",
      "Epoch 926/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7264 - val_loss: 0.6978 - val_accuracy: 0.6741\n",
      "Epoch 927/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7328 - val_loss: 0.6952 - val_accuracy: 0.6772\n",
      "Epoch 928/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7289 - val_loss: 0.7019 - val_accuracy: 0.6646\n",
      "Epoch 929/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7328 - val_loss: 0.6990 - val_accuracy: 0.6709\n",
      "Epoch 930/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7328 - val_loss: 0.7034 - val_accuracy: 0.6646\n",
      "Epoch 931/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7366 - val_loss: 0.7038 - val_accuracy: 0.6677\n",
      "Epoch 932/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7314 - val_loss: 0.7086 - val_accuracy: 0.6614\n",
      "Epoch 933/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7307 - val_loss: 0.7042 - val_accuracy: 0.6677\n",
      "Epoch 934/1000\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7268 - val_loss: 0.7080 - val_accuracy: 0.6646\n",
      "Epoch 935/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7321 - val_loss: 0.7064 - val_accuracy: 0.6677\n",
      "Epoch 936/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7271 - val_loss: 0.7043 - val_accuracy: 0.6709\n",
      "Epoch 937/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7282 - val_loss: 0.7037 - val_accuracy: 0.6709\n",
      "Epoch 938/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7307 - val_loss: 0.7045 - val_accuracy: 0.6614\n",
      "Epoch 939/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7282 - val_loss: 0.7007 - val_accuracy: 0.6677\n",
      "Epoch 940/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7300 - val_loss: 0.7063 - val_accuracy: 0.6677\n",
      "Epoch 941/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7286 - val_loss: 0.7064 - val_accuracy: 0.6646\n",
      "Epoch 942/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7314 - val_loss: 0.7042 - val_accuracy: 0.6614\n",
      "Epoch 943/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7247 - val_loss: 0.7052 - val_accuracy: 0.6614\n",
      "Epoch 944/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7293 - val_loss: 0.7044 - val_accuracy: 0.6646\n",
      "Epoch 945/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7264 - val_loss: 0.7069 - val_accuracy: 0.6709\n",
      "Epoch 946/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7286 - val_loss: 0.7118 - val_accuracy: 0.6582\n",
      "Epoch 947/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7338 - val_loss: 0.7125 - val_accuracy: 0.6582\n",
      "Epoch 948/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7293 - val_loss: 0.7089 - val_accuracy: 0.6677\n",
      "Epoch 949/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7268 - val_loss: 0.7113 - val_accuracy: 0.6646\n",
      "Epoch 950/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7261 - val_loss: 0.7075 - val_accuracy: 0.6677\n",
      "Epoch 951/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7293 - val_loss: 0.7103 - val_accuracy: 0.6582\n",
      "Epoch 952/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7264 - val_loss: 0.7072 - val_accuracy: 0.6614\n",
      "Epoch 953/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7391 - val_loss: 0.7102 - val_accuracy: 0.6614\n",
      "Epoch 954/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7310 - val_loss: 0.7085 - val_accuracy: 0.6614\n",
      "Epoch 955/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7243 - val_loss: 0.7089 - val_accuracy: 0.6646\n",
      "Epoch 956/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7275 - val_loss: 0.7066 - val_accuracy: 0.6582\n",
      "Epoch 957/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7307 - val_loss: 0.7056 - val_accuracy: 0.6582\n",
      "Epoch 958/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7286 - val_loss: 0.7060 - val_accuracy: 0.6614\n",
      "Epoch 959/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7293 - val_loss: 0.7055 - val_accuracy: 0.6582\n",
      "Epoch 960/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7286 - val_loss: 0.7081 - val_accuracy: 0.6709\n",
      "Epoch 961/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7282 - val_loss: 0.7086 - val_accuracy: 0.6551\n",
      "Epoch 962/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7286 - val_loss: 0.7072 - val_accuracy: 0.6614\n",
      "Epoch 963/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7184 - val_loss: 0.7097 - val_accuracy: 0.6582\n",
      "Epoch 964/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7377 - val_loss: 0.7077 - val_accuracy: 0.6709\n",
      "Epoch 965/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7310 - val_loss: 0.7100 - val_accuracy: 0.6582\n",
      "Epoch 966/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7300 - val_loss: 0.7101 - val_accuracy: 0.6614\n",
      "Epoch 967/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7324 - val_loss: 0.7104 - val_accuracy: 0.6614\n",
      "Epoch 968/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7286 - val_loss: 0.7155 - val_accuracy: 0.6614\n",
      "Epoch 969/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7293 - val_loss: 0.7092 - val_accuracy: 0.6741\n",
      "Epoch 970/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7321 - val_loss: 0.7137 - val_accuracy: 0.6741\n",
      "Epoch 971/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7335 - val_loss: 0.7128 - val_accuracy: 0.6677\n",
      "Epoch 972/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7366 - val_loss: 0.7155 - val_accuracy: 0.6582\n",
      "Epoch 973/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7278 - val_loss: 0.7187 - val_accuracy: 0.6614\n",
      "Epoch 974/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7303 - val_loss: 0.7183 - val_accuracy: 0.6582\n",
      "Epoch 975/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7317 - val_loss: 0.7195 - val_accuracy: 0.6487\n",
      "Epoch 976/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7300 - val_loss: 0.7098 - val_accuracy: 0.6582\n",
      "Epoch 977/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7328 - val_loss: 0.7117 - val_accuracy: 0.6614\n",
      "Epoch 978/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7250 - val_loss: 0.7099 - val_accuracy: 0.6677\n",
      "Epoch 979/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7342 - val_loss: 0.7126 - val_accuracy: 0.6677\n",
      "Epoch 980/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7296 - val_loss: 0.7136 - val_accuracy: 0.6677\n",
      "Epoch 981/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7300 - val_loss: 0.7140 - val_accuracy: 0.6614\n",
      "Epoch 982/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7310 - val_loss: 0.7211 - val_accuracy: 0.6614\n",
      "Epoch 983/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7293 - val_loss: 0.7157 - val_accuracy: 0.6646\n",
      "Epoch 984/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7366 - val_loss: 0.7158 - val_accuracy: 0.6677\n",
      "Epoch 985/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7282 - val_loss: 0.7232 - val_accuracy: 0.6614\n",
      "Epoch 986/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7377 - val_loss: 0.7203 - val_accuracy: 0.6551\n",
      "Epoch 987/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7289 - val_loss: 0.7261 - val_accuracy: 0.6456\n",
      "Epoch 988/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7303 - val_loss: 0.7232 - val_accuracy: 0.6487\n",
      "Epoch 989/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7366 - val_loss: 0.7196 - val_accuracy: 0.6646\n",
      "Epoch 990/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7254 - val_loss: 0.7198 - val_accuracy: 0.6646\n",
      "Epoch 991/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7264 - val_loss: 0.7182 - val_accuracy: 0.6614\n",
      "Epoch 992/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7338 - val_loss: 0.7168 - val_accuracy: 0.6551\n",
      "Epoch 993/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7338 - val_loss: 0.7149 - val_accuracy: 0.6614\n",
      "Epoch 994/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7335 - val_loss: 0.7109 - val_accuracy: 0.6677\n",
      "Epoch 995/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7317 - val_loss: 0.7194 - val_accuracy: 0.6551\n",
      "Epoch 996/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7240 - val_loss: 0.7264 - val_accuracy: 0.6614\n",
      "Epoch 997/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7359 - val_loss: 0.7198 - val_accuracy: 0.6646\n",
      "Epoch 998/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7356 - val_loss: 0.7251 - val_accuracy: 0.6582\n",
      "Epoch 999/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7387 - val_loss: 0.7257 - val_accuracy: 0.6519\n",
      "Epoch 1000/1000\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7307 - val_loss: 0.7244 - val_accuracy: 0.6551\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=( 1, X_train.shape[1])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Using sigmoid for binary classification\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Use binary_crossentropy for binary classification\n",
    "\n",
    "# Reshape input data to be 3D [samples, timesteps, features] for LSTM\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=1000, batch_size=32, validation_split=0.1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
